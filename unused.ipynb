{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f39475-0cc3-448c-afb9-0c055d5c2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightage(word,text,number_of_documents=1):\n",
    "    \n",
    "    number_of_times_word_appeared = len(word_list)\n",
    "\n",
    "    tf = number_of_times_word_appeared/float(len(text))\n",
    "\n",
    "    idf = np.log((number_of_documents)/float(number_of_times_word_appeared))\n",
    "    \n",
    "    tf_idf = tf*idf\n",
    "    \n",
    "    return number_of_times_word_appeared, tf, idf, tf_idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12e6f5-ee13-49ec-9726-ba3df672e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brauch ich das noch?\n",
    "def word_count(text):\n",
    "    counts = dict()\n",
    "    words = text.split(\" \")\n",
    "\n",
    "    #print(words)\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "\n",
    "    return words, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de90d96-d70c-44da-b09d-4cf6ecc81577",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_df=3, min_df=0, stop_words=stop_words, max_features=10000, ngram_range=(1,3))\n",
    "fittedStopwords = [\"dummy\" for dummy in range(len(corpus))]\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = [corpus[i]]\n",
    "    fittedStopwords[i] = cv.fit_transform(corpus[i])\n",
    "print(fittedStopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31304c71-fb71-41c9-9557-6dfebb3f21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Iteration 端ber Texte\n",
    "for i in range(len(corpus)):\n",
    "    df_keys = {'keywords': [], #Erstellung Dictionary f端r nachher DataFrame\n",
    "              'number_of_times_word_appeared': [],\n",
    "              'idf': [],\n",
    "              'tf': [],\n",
    "              'tf_idf': []}\n",
    "    for keyword in keywords[i]: #Iteration 端ber keywords pro Text\n",
    "        word_list = re.findall(keyword,corpus[i]) #Finde die keywords wieder im Text\n",
    "        if len(word_list) >= 1: #Falls keyword gefunden\n",
    "            curArray = []\n",
    "            curArray = weightage(keyword, corpus[i])    \n",
    "            \n",
    "            #if keyword not in df_keys.get('keywords') : #funktioniert so nicht\n",
    "            #F端llung des Dictionary anhand der Funktion weightage\n",
    "            df_keys['keywords'].append([keyword])\n",
    "            df_keys['number_of_times_word_appeared'].append(curArray[0])\n",
    "            df_keys['tf'].append(curArray[1])\n",
    "            df_keys['idf'].append(curArray[2])\n",
    "            df_keys['tf_idf'].append(curArray[3])\n",
    "#Umwandlung in Dataframe\n",
    "    df = pd.DataFrame(df_keys)\n",
    "    \n",
    "    df=df.loc[df.astype(str).drop_duplicates(subset='keywords').index]\n",
    "    df = df.sort_values('tf_idf',ascending=True)\n",
    "    df.head(25).to_csv(str(i)+'_Keywords.csv') #Erstellung csv pro Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4bf9e7-086b-40a1-aeef-39dc02913e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Output labels\n",
    "candidate_labels = [\"Topic\", \"No Topic\"]\n",
    "\n",
    "# device=0 for GPU usage\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\", device=0)\n",
    "\n",
    "# Sample code to see labels for first five rows in df\n",
    "for i in range(len(corpus)):\n",
    "  input_text = corpus[i]\n",
    "  \n",
    "  # multi_label=True will return confidence score for both labels independently \n",
    "  model_dict = classifier(input_text, candidate_labels, multi_label=True)\n",
    "\n",
    "  # Zip results to dict\n",
    "  result_dict = dict(zip(model_dict.get('labels'), model_dict.get('scores')))\n",
    "  \n",
    "  # Print confidence scores\n",
    "  print(\"Input Text for the model : \", input_text)\n",
    "  print(\"Confidence Score for Topic Class : \", result_dict.get('Topic'))\n",
    "  print(\"Confidence Score for No-Topic Class : \", result_dict.get('No Topic'), end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
