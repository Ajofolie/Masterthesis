{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589b2dfa-c468-4008-806e-417a2c393d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Jana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Jana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Jana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import PyPDF2 as pdf\n",
    "import numpy\n",
    "#from xml.dom import DomstringSizeErr\n",
    "#nltk\n",
    "import nltk\n",
    "nltk.download('punkt') #nltk.tokenize.punkt module.  https://www.nltk.org/_modules/nltk/tokenize/punkt.html\n",
    "nltk.download('averaged_perceptron_tagger') #nltk.tag.perceptron module, https://explosion.ai/blog/part-of-speech-pos-tagger-in-python\n",
    "nltk.download('maxent_ne_chunker') #https://www.kaggle.com/datasets/nltkdata/maxent-ne-chunker , https://www.tomaarsen.com/nltk/api/nltk.chunk.named_entity.html\n",
    "nltk.download('words') #list of str https://www.nltk.org/api/nltk.corpus.reader.html?highlight=words#nltk.corpus.reader.AlignedCorpusReader.words\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('omw-1.4')\n",
    "#Spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "#Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stoplist = stopwords.words('english')\n",
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "import fitz\n",
    "\n",
    "import aspose.words as aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2bcca5-160e-4669-afee-2cf75c800040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_path = 'C:/Users/Jana/OneDrive/Dokumente/Desktop/Uni/Master/Thesis/PaperDatenextraktion/AAAI2019.pdf'\n",
    "#pdf_path = open(str(filePath)+'Data Mining Tools.pdf', 'rb')\n",
    "\n",
    "doc = fitz.open(pdf_path)\n",
    "page = doc[0]\n",
    "exmpl = page.get_text(\"text\")\n",
    "\n",
    "doc2=aw.Document(pdf_path)\n",
    "doc2.save('C:/Users/Jana/OneDrive/Dokumente/Desktop/Uni/Master/Thesis/PaperDatenextraktion/AAAI2019.md')\n",
    "\n",
    "#print(exmpl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9060be61-c0db-405e-930d-96947439afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zero-Shot', 'Object', 'Detection', 'with', 'Textual', 'Descriptions', 'Zhihui', 'Li1', ',', 'Lina', 'Yao1', ',', 'Xiaoqin', 'Zhang2', ',', 'Xianzhi', 'Wang3', ',', 'Salil', 'Kanhere1', ',', 'and', 'Huaxiang', 'Zhang4∗', '1School', 'of', 'Computer', 'Science', 'and', 'Engineering', ',', 'University', 'of', 'New', 'South', 'Wales', '2College', 'of', 'Mathematics', 'and', 'Information', 'Science', ',', 'Wenzhou', 'University', '3School', 'of', 'Software', ',', 'University', 'of', 'Technology', 'Sydney', '4School', 'of', 'Information', 'Science', 'and', 'Engineering', ',', 'Shandong', 'Normal', 'University', 'Abstract', 'Object', 'detection', 'is', 'important', 'in', 'real-world', 'applications', '.', 'Exist-', 'ing', 'methods', 'mainly', 'focus', 'on', 'object', 'detection', 'with', 'sufﬁcient', 'labelled', 'training', 'data', 'or', 'zero-shot', 'object', 'detection', 'with', 'only', 'concept', 'names', '.', 'In', 'this', 'paper', ',', 'we', 'address', 'the', 'challenging', 'prob-', 'lem', 'of', 'zero-shot', 'object', 'detection', 'with', 'natural', 'language', 'de-', 'scription', ',', 'which', 'aims', 'to', 'simultaneously', 'detect', 'and', 'recognize', 'novel', 'concept', 'instances', 'with', 'textual', 'descriptions', '.', 'We', 'propose', 'a', 'novel', 'deep', 'learning', 'framework', 'to', 'jointly', 'learn', 'visual', 'units', ',', 'visual-unit', 'attention', 'and', 'word-level', 'attention', ',', 'which', 'are', 'com-', 'bined', 'to', 'achieve', 'word-proposal', 'afﬁnity', 'by', 'an', 'element-wise', 'multiplication', '.', 'To', 'the', 'best', 'of', 'our', 'knowledge', ',', 'this', 'is', 'the', 'ﬁrst', 'work', 'on', 'zero-shot', 'object', 'detection', 'with', 'textual', 'descriptions', '.', 'Since', 'there', 'is', 'no', 'directly', 'related', 'work', 'in', 'the', 'literature', ',', 'we', 'investigate', 'plausible', 'solutions', 'based', 'on', 'existing', 'zero-shot', 'ob-', 'ject', 'detection', 'for', 'a', 'fair', 'comparison', '.', 'We', 'conduct', 'extensive', 'experiments', 'on', 'three', 'challenging', 'benchmark', 'datasets', '.', 'The', 'extensive', 'experimental', 'results', 'conﬁrm', 'the', 'superiority', 'of', 'the', 'proposed', 'model', '.', 'Introduction', 'In', 'the', 'last', 'decade', ',', 'researchers', 'have', 'made', 'promising', 'progress', 'in', 'object', 'detection', 'Girshick', '[', '2015', ']', ',', 'Ren', 'et', 'al', '.', '[', '2015', ',', '2017', ']', ',', 'Lin', 'et', 'al', '.', '[', '2017', ']', '.', 'Most', 'of', 'these', 'achievements', 'rely', 'on', 'the', 'collection', 'of', 'large-scale', 'labeled', 'training', 'data', '.', 'Although', 're-', 'searchers', 'have', 'struggled', 'to', 'acquire', 'larger', 'datasets', 'with', 'a', 'broader', 'set', 'of', 'categories', ',', 'the', 'processing', 'procedure', 'is', 'time-', 'consuming', 'and', 'tedious', '.', 'Furthermore', ',', 'it', 'is', 'impossible', 'to', 'col-', 'lect', 'enough', 'training', 'data', 'for', 'rare', 'concepts', ',', 'i.e', '.', 'Okapia', '.', 'There-', 'fore', ',', 'a', 'challenging', 'problem', 'is', 'how', 'to', 'simultaneously', 'recog-', 'nize', 'and', 'locate', 'these', 'novel', 'object', 'instances', 'with', 'no', 'training', 'samples', '.', 'Zero-shot', 'learning', 'has', 'been', 'widely', 'used', 'to', 'tackle', 'the', 'problem', 'of', 'data', 'scarcity', 'Akata', 'et', 'al', '.', '[', '2016', ']', ',', 'Frome', 'et', 'al', '.', '[', '2013', ']', ',', 'Lampert', 'et', 'al', '.', '[', '2009', ']', ',', 'Zhang', 'et', 'al', '.', '[', '2017', ']', ',', 'Zhang', 'and', 'Saligrama', '[', '2015', ']', ',', 'Rahman', 'et', 'al', '.', '[', '2018', ']', ',', 'Mikolov', 'et', 'al', '.', '[', '2013', ']', '.', 'Most', 'of', 'these', 'works', 'focus', 'on', 'the', 'concept', 'classiﬁca-', 'tion', 'problem', '.', 'Although', 'it', 'remains', 'a', 'challenging', 'and', 'unsolved', 'problem', ',', 'there', 'is', 'still', 'a', 'large', 'gap', 'between', 'the', 'problem', 'setting', 'and', 'real-world', 'scenarios', 'in', 'the', 'following', 'aspects', '.', 'Firstly', ',', 'in', 'most', 'zero-shot', 'learning', 'benchmark', 'datasets', 'Welinder', 'et', 'al', '.', '[', '2010', ']', ',', 'Nilsback', 'and', 'Zisserman', '[', '2008', ']', ',', 'Russakovsky', 'et', 'al', '.', '[', '2015', ']', ',', 'each', 'image', 'has', 'only', 'one', 'dominant', 'object', ',', 'while', 'in', 'real-world', 'applications', ',', 'multiple', 'objects', 'may', 'appear', 'in', 'a', 'single', 'image', '.', 'Secondly', ',', 'most', 'of', 'the', 'zero-shot', 'classiﬁcation', 'methods', 'are', 'based', 'on', 'attributes', 'and', 'semantic', 'descriptions', ',', 'which', 'can', 'not', 'be', 'directly', 'applied', 'to', 'zero-shot', 'detection', 'in', 'the', 'entire', 'scene', 'image', '.', 'Thirdly', ',', 'the', 'setting', 'of', 'zero-shot', 'learning', 'does', 'not', 'consider', 'occlusions', 'and', 'clutter', ',', 'which', 'commonly', 'exist', 'in', 'real-world', 'applications', '.', 'To', 'close', 'this', 'gap', ',', 'Rahman', 'et', 'al', '.', '[', '2018', ']', 'introduced', 'a', 'new', '“', 'zero-shot', 'object', 'detection', '”', '(', 'ZSD', ')', 'problem', 'setting', 'method', ',', 'which', 'aims', 'at', 'concurrently', 'detecting', 'and', 'recognizing', 'novel', 'instance', 'in', 'the', 'absence', 'of', 'any', 'training', 'examples', '.', 'Although', 'the', 'data-scarcity', 'challenge', 'exists', 'for', 'a', 'large', 'num-', 'ber', 'of', 'categories', 'in', 'real-world', 'applications', ',', 'there', 'is', 'a', 'massive', 'amount', 'of', 'textual', 'data', 'for', 'these', 'categories', '.', 'These', 'data', 'arrive', 'in', 'the', 'form', 'of', 'dictionary', 'entries', ',', 'online', 'encyclopedias', 'and', 'other', 'online', 'resources', '.', 'For', 'example', ',', 'English', 'Wikipedia', 'has', '5,645,010', 'articles', 'on', 'its', 'site', ',', 'which', 'provides', 'a', 'rich', 'knowl-', 'edge', 'base', 'for', 'different', 'topics', '.', 'The', 'major', 'problem', 'we', 'focus', 'on', 'in', 'this', 'paper', 'is', 'how', 'to', 'simultaneously', 'recognize', 'and', 'locate', 'novel', 'object', 'instances', 'using', 'purely', 'unstructured', 'textual', 'descriptions', 'with', 'no', 'train-', 'ing', 'samples', '.', 'In', 'other', 'words', ',', 'our', 'goal', 'is', 'to', 'concurrently', 'link', 'visual', 'image', 'features', 'with', 'the', 'semantic', 'label', 'information', 'where', 'the', 'descriptions', 'of', 'novel', 'concepts', 'are', 'presented', 'in', 'the', 'form', 'of', 'natural', 'languages', ',', 'i.e', '.', 'online', 'encyclopedias', '.', 'We', 'de-', 'sign', 'a', 'novel', 'deep', 'learning', 'framework', 'for', 'zero-shot', 'object', 'de-', 'tection', 'with', 'textual', 'description', '.', 'The', 'proposed', 'network', 'takes', 'a', 'description', 'and', 'an', 'image', 'as', 'input', 'and', 'outputs', 'the', 'afﬁnities', 'between', 'the', 'description', 'and', 'the', 'object', 'proposals', 'in', 'the', 'im-', 'age', '.', 'We', 'process', 'the', 'textual', 'description', 'in', 'a', 'word-by-word', 'fashion', 'with', 'word-LSTM', '.', 'For', 'each', 'word', 'in', 'the', 'description', ',', 'we', 'achieve', 'unit-level', 'attentions', 'for', 'different', 'units', 'using', 'the', 'LSTM', '.', 'Each', 'unit', 'determines', 'whether', 'a', 'speciﬁc', 'object', 'pattern', 'exists', 'in', 'the', 'object', 'proposal', '.', 'The', 'contributions', 'of', 'different', 'units', 'are', 'weighted', 'by', 'the', 'visual-unit', 'attention', 'mechanism', '.', 'To', 'step', 'further', ',', 'we', 'also', 'study', 'word-level', 'attention', 'which', 'learns', 'the', 'importance', 'of', 'different', 'words', 'for', 'adaptive', 'word-level', 'weighting', '.', 'We', 'achieve', 'the', 'ﬁnal', 'afﬁnity', 'by', 'averaging', 'over', 'all', 'units', '’', 'responses', 'for', 'all', 'words', '.', 'We', 'conduct', 'experiments', 'to', 'conﬁrm', 'that', 'both', 'visual', 'unit-level', 'attention', 'and', 'word-level', 'attention', 'contribute', 'to', 'the', 'good', 'performance', 'of', 'the', 'proposed', 'model', '.', 'Compared', 'with', 'the', 'related', 'works', 'in', 'the', 'literature', ',']\n"
     ]
    }
   ],
   "source": [
    "#Tokenisierung einzelner Wörter\n",
    "tokens = nltk.word_tokenize(exmpl)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf4dfb5-3c04-4c38-8114-22b9a4a1b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZeroShot', 'Object', 'Detection', 'Textual', 'Descriptions', 'Zhihui', 'Li1', '', 'Lina', 'Yao1', '', 'Xiaoqin', 'Zhang2', '', 'Xianzhi', 'Wang3', '', 'Salil', 'Kanhere1', '', 'Huaxiang', 'Zhang4∗', '1School', 'Computer', 'Science', 'Engineering', '', 'University', 'New', 'South', 'Wales', '2College', 'Mathematics', 'Information', 'Science', '', 'Wenzhou', 'University', '3School', 'Software', '', 'University', 'Technology', 'Sydney', '4School', 'Information', 'Science', 'Engineering', '', 'Shandong', 'Normal', 'University', 'Abstract', 'Object', 'detection', 'important', 'realworld', 'applications', '', 'Exist', 'ing', 'methods', 'mainly', 'focus', 'object', 'detection', 'sufﬁcient', 'labelled', 'training', 'data', 'zeroshot', 'object', 'detection', 'concept', 'names', '', 'In', 'paper', '', 'address', 'challenging', 'prob', 'lem', 'zeroshot', 'object', 'detection', 'natural', 'language', 'de', 'scription', '', 'aims', 'simultaneously', 'detect', 'recognize', 'novel', 'concept', 'instances', 'textual', 'descriptions', '', 'We', 'propose', 'novel', 'deep', 'learning', 'framework', 'jointly', 'learn', 'visual', 'units', '', 'visualunit', 'attention', 'wordlevel', 'attention', '', 'com', 'bined', 'achieve', 'wordproposal', 'afﬁnity', 'elementwise', 'multiplication', '', 'To', 'best', 'knowledge', '', 'ﬁrst', 'work', 'zeroshot', 'object', 'detection', 'textual', 'descriptions', '', 'Since', 'directly', 'related', 'work', 'literature', '', 'investigate', 'plausible', 'solutions', 'based', 'existing', 'zeroshot', 'ob', 'ject', 'detection', 'fair', 'comparison', '', 'We', 'conduct', 'extensive', 'experiments', 'three', 'challenging', 'benchmark', 'datasets', '', 'The', 'extensive', 'experimental', 'results', 'conﬁrm', 'superiority', 'proposed', 'model', '', 'Introduction', 'In', 'last', 'decade', '', 'researchers', 'made', 'promising', 'progress', 'object', 'detection', 'Girshick', '', '2015', '', '', 'Ren', 'et', 'al', '', '', '2015', '', '2017', '', '', 'Lin', 'et', 'al', '', '', '2017', '', '', 'Most', 'achievements', 'rely', 'collection', 'largescale', 'labeled', 'training', 'data', '', 'Although', 'searchers', 'struggled', 'acquire', 'larger', 'datasets', 'broader', 'set', 'categories', '', 'processing', 'procedure', 'time', 'consuming', 'tedious', '', 'Furthermore', '', 'impossible', 'col', 'lect', 'enough', 'training', 'data', 'rare', 'concepts', '', 'ie', '', 'Okapia', '', 'There', 'fore', '', 'challenging', 'problem', 'simultaneously', 'recog', 'nize', 'locate', 'novel', 'object', 'instances', 'training', 'samples', '', 'Zeroshot', 'learning', 'widely', 'used', 'tackle', 'problem', 'data', 'scarcity', 'Akata', 'et', 'al', '', '', '2016', '', '', 'Frome', 'et', 'al', '', '', '2013', '', '', 'Lampert', 'et', 'al', '', '', '2009', '', '', 'Zhang', 'et', 'al', '', '', '2017', '', '', 'Zhang', 'Saligrama', '', '2015', '', '', 'Rahman', 'et', 'al', '', '', '2018', '', '', 'Mikolov', 'et', 'al', '', '', '2013', '', '', 'Most', 'works', 'focus', 'concept', 'classiﬁca', 'tion', 'problem', '', 'Although', 'remains', 'challenging', 'unsolved', 'problem', '', 'still', 'large', 'gap', 'problem', 'setting', 'realworld', 'scenarios', 'following', 'aspects', '', 'Firstly', '', 'zeroshot', 'learning', 'benchmark', 'datasets', 'Welinder', 'et', 'al', '', '', '2010', '', '', 'Nilsback', 'Zisserman', '', '2008', '', '', 'Russakovsky', 'et', 'al', '', '', '2015', '', '', 'image', 'one', 'dominant', 'object', '', 'realworld', 'applications', '', 'multiple', 'objects', 'may', 'appear', 'single', 'image', '', 'Secondly', '', 'zeroshot', 'classiﬁcation', 'methods', 'based', 'attributes', 'semantic', 'descriptions', '', 'directly', 'applied', 'zeroshot', 'detection', 'entire', 'scene', 'image', '', 'Thirdly', '', 'setting', 'zeroshot', 'learning', 'consider', 'occlusions', 'clutter', '', 'commonly', 'exist', 'realworld', 'applications', '', 'To', 'close', 'gap', '', 'Rahman', 'et', 'al', '', '', '2018', '', 'introduced', 'new', '“', 'zeroshot', 'object', 'detection', '”', '', 'ZSD', '', 'problem', 'setting', 'method', '', 'aims', 'concurrently', 'detecting', 'recognizing', 'novel', 'instance', 'absence', 'training', 'examples', '', 'Although', 'datascarcity', 'challenge', 'exists', 'large', 'num', 'ber', 'categories', 'realworld', 'applications', '', 'massive', 'amount', 'textual', 'data', 'categories', '', 'These', 'data', 'arrive', 'form', 'dictionary', 'entries', '', 'online', 'encyclopedias', 'online', 'resources', '', 'For', 'example', '', 'English', 'Wikipedia', '5645010', 'articles', 'site', '', 'provides', 'rich', 'knowl', 'edge', 'base', 'different', 'topics', '', 'The', 'major', 'problem', 'focus', 'paper', 'simultaneously', 'recognize', 'locate', 'novel', 'object', 'instances', 'using', 'purely', 'unstructured', 'textual', 'descriptions', 'train', 'ing', 'samples', '', 'In', 'words', '', 'goal', 'concurrently', 'link', 'visual', 'image', 'features', 'semantic', 'label', 'information', 'descriptions', 'novel', 'concepts', 'presented', 'form', 'natural', 'languages', '', 'ie', '', 'online', 'encyclopedias', '', 'We', 'de', 'sign', 'novel', 'deep', 'learning', 'framework', 'zeroshot', 'object', 'de', 'tection', 'textual', 'description', '', 'The', 'proposed', 'network', 'takes', 'description', 'image', 'input', 'outputs', 'afﬁnities', 'description', 'object', 'proposals', 'im', 'age', '', 'We', 'process', 'textual', 'description', 'wordbyword', 'fashion', 'wordLSTM', '', 'For', 'word', 'description', '', 'achieve', 'unitlevel', 'attentions', 'different', 'units', 'using', 'LSTM', '', 'Each', 'unit', 'determines', 'whether', 'speciﬁc', 'object', 'pattern', 'exists', 'object', 'proposal', '', 'The', 'contributions', 'different', 'units', 'weighted', 'visualunit', 'attention', 'mechanism', '', 'To', 'step', '', 'also', 'study', 'wordlevel', 'attention', 'learns', 'importance', 'different', 'words', 'adaptive', 'wordlevel', 'weighting', '', 'We', 'achieve', 'ﬁnal', 'afﬁnity', 'averaging', 'units', '’', 'responses', 'words', '', 'We', 'conduct', 'experiments', 'conﬁrm', 'visual', 'unitlevel', 'attention', 'wordlevel', 'attention', 'contribute', 'good', 'performance', 'proposed', 'model', '', 'Compared', 'related', 'works', 'literature', '']\n"
     ]
    }
   ],
   "source": [
    "#tokens=[word.lower() for word in tokens if word.isalpha()]\n",
    "import string\n",
    "\n",
    "tokens = [''.join(letter for letter in word if letter not in string.punctuation) for word in tokens if word]\n",
    "#print(tokens)\n",
    "\n",
    "# Herasufiltern Stop words\n",
    "exmpl_filtered_sw = []\n",
    "for w in tokens:\n",
    "    if w not in stopset:\n",
    "        exmpl_filtered_sw.append(w)\n",
    "print(exmpl_filtered_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4d95fd-a73a-465d-9b43-d6b985e2eb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ZeroShot', 'NNP'), ('Object', 'NNP'), ('Detection', 'NNP'), ('Textual', 'NNP'), ('Descriptions', 'NNP'), ('Zhihui', 'NNP'), ('Li1', 'NNP'), ('', 'NNP'), ('Lina', 'NNP'), ('Yao1', 'NNP'), ('', 'NNP'), ('Xiaoqin', 'NNP'), ('Zhang2', 'NNP'), ('', 'NNP'), ('Xianzhi', 'NNP'), ('Wang3', 'NNP'), ('', 'NNP'), ('Salil', 'NNP'), ('Kanhere1', 'NNP'), ('', 'NNP'), ('Huaxiang', 'NNP'), ('Zhang4∗', 'NNP'), ('1School', 'CD'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Engineering', 'NNP'), ('', 'NNP'), ('University', 'NNP'), ('New', 'NNP'), ('South', 'NNP'), ('Wales', 'NNP'), ('2College', 'CD'), ('Mathematics', 'NNPS'), ('Information', 'NNP'), ('Science', 'NNP'), ('', 'NNP'), ('Wenzhou', 'NNP'), ('University', 'NNP'), ('3School', 'CD'), ('Software', 'NNP'), ('', 'NNP'), ('University', 'NNP'), ('Technology', 'NNP'), ('Sydney', 'NNP'), ('4School', 'CD'), ('Information', 'NNP'), ('Science', 'NNP'), ('Engineering', 'NNP'), ('', 'NNP'), ('Shandong', 'NNP'), ('Normal', 'NNP'), ('University', 'NNP'), ('Abstract', 'NNP'), ('Object', 'NNP'), ('detection', 'NN'), ('important', 'JJ'), ('realworld', 'NN'), ('applications', 'NNS'), ('', 'VBP'), ('Exist', 'NNP'), ('ing', 'VBG'), ('methods', 'NNS'), ('mainly', 'RB'), ('focus', 'VBP'), ('object', 'JJ'), ('detection', 'NN'), ('sufﬁcient', 'NN'), ('labelled', 'VBD'), ('training', 'NN'), ('data', 'NNS'), ('zeroshot', 'NN'), ('object', 'JJ'), ('detection', 'NN'), ('concept', 'NN'), ('names', 'NNS'), ('', 'VBP'), ('In', 'IN'), ('paper', 'NN'), ('', 'NN'), ('address', 'NN'), ('challenging', 'VBG'), ('prob', 'JJ'), ('lem', 'NN'), ('zeroshot', 'NN'), ('object', 'JJ'), ('detection', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('de', 'FW'), ('scription', 'NN'), ('', 'NN'), ('aims', 'VBZ'), ('simultaneously', 'RB'), ('detect', 'JJ'), ('recognize', 'NN'), ('novel', 'NN'), ('concept', 'NN'), ('instances', 'NNS'), ('textual', 'JJ'), ('descriptions', 'NNS'), ('', 'IN'), ('We', 'PRP'), ('propose', 'VBP'), ('novel', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('framework', 'NN'), ('jointly', 'RB'), ('learn', 'JJ'), ('visual', 'JJ'), ('units', 'NNS'), ('', 'VBP'), ('visualunit', 'JJ'), ('attention', 'NN'), ('wordlevel', 'NN'), ('attention', 'NN'), ('', 'NNP'), ('com', 'NN'), ('bined', 'VBD'), ('achieve', 'JJ'), ('wordproposal', 'NN'), ('afﬁnity', 'NN'), ('elementwise', 'NN'), ('multiplication', 'NN'), ('', 'NN'), ('To', 'TO'), ('best', 'VB'), ('knowledge', 'NN'), ('', 'NNP'), ('ﬁrst', 'NNP'), ('work', 'NN'), ('zeroshot', 'NN'), ('object', 'JJ'), ('detection', 'NN'), ('textual', 'JJ'), ('descriptions', 'NNS'), ('', 'VBP'), ('Since', 'IN'), ('directly', 'RB'), ('related', 'VBN'), ('work', 'NN'), ('literature', 'NN'), ('', 'JJ'), ('investigate', 'NN'), ('plausible', 'JJ'), ('solutions', 'NNS'), ('based', 'VBN'), ('existing', 'VBG'), ('zeroshot', 'JJ'), ('ob', 'NN'), ('ject', 'NN'), ('detection', 'NN'), ('fair', 'JJ'), ('comparison', 'NN'), ('', 'IN'), ('We', 'PRP'), ('conduct', 'VBP'), ('extensive', 'JJ'), ('experiments', 'NNS'), ('three', 'CD'), ('challenging', 'VBG'), ('benchmark', 'NN'), ('datasets', 'NNS'), ('', 'VBP'), ('The', 'DT'), ('extensive', 'JJ'), ('experimental', 'JJ'), ('results', 'NNS'), ('conﬁrm', 'VBP'), ('superiority', 'NN'), ('proposed', 'VBN'), ('model', 'NN'), ('', 'CD'), ('Introduction', 'NNP'), ('In', 'IN'), ('last', 'JJ'), ('decade', 'NN'), ('', 'NN'), ('researchers', 'NNS'), ('made', 'VBD'), ('promising', 'VBG'), ('progress', 'NN'), ('object', 'JJ'), ('detection', 'NN'), ('Girshick', 'NNP'), ('', 'NN'), ('2015', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Ren', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('', 'NNP'), ('', 'NN'), ('2015', 'CD'), ('', 'NN'), ('2017', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Lin', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('', 'NNP'), ('', 'NN'), ('2017', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Most', 'JJS'), ('achievements', 'NNS'), ('rely', 'VBP'), ('collection', 'JJ'), ('largescale', 'NN'), ('labeled', 'VBD'), ('training', 'NN'), ('data', 'NNS'), ('', 'NNP'), ('Although', 'IN'), ('searchers', 'NNS'), ('struggled', 'VBD'), ('acquire', 'VB'), ('larger', 'JJR'), ('datasets', 'NNS'), ('broader', 'VBP'), ('set', 'VBN'), ('categories', 'NNS'), ('', 'VBP'), ('processing', 'VBG'), ('procedure', 'NN'), ('time', 'NN'), ('consuming', 'VBG'), ('tedious', 'JJ'), ('', 'NNS'), ('Furthermore', 'RB'), ('', 'VBP'), ('impossible', 'JJ'), ('col', 'NN'), ('lect', 'JJ'), ('enough', 'RB'), ('training', 'NN'), ('data', 'NNS'), ('rare', 'JJ'), ('concepts', 'NNS'), ('', 'VBP'), ('ie', 'JJ'), ('', 'NNP'), ('Okapia', 'NNP'), ('', 'NNP'), ('There', 'EX'), ('fore', 'RB'), ('', 'JJ'), ('challenging', 'VBG'), ('problem', 'NN'), ('simultaneously', 'RB'), ('recog', 'VBZ'), ('nize', 'JJ'), ('locate', 'NN'), ('novel', 'NN'), ('object', 'JJ'), ('instances', 'NNS'), ('training', 'VBG'), ('samples', 'NNS'), ('', 'NNP'), ('Zeroshot', 'NNP'), ('learning', 'VBG'), ('widely', 'RB'), ('used', 'VBN'), ('tackle', 'NN'), ('problem', 'NN'), ('data', 'NNS'), ('scarcity', 'NN'), ('Akata', 'NNP'), ('et', 'CC'), ('al', 'JJ'), ('', 'NNP'), ('', 'NN'), ('2016', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Frome', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('', 'NNP'), ('', 'NN'), ('2013', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Lampert', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('', 'NNP'), ('', 'NN'), ('2009', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Zhang', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('', 'NNP'), ('', 'NN'), ('2017', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Zhang', 'NNP'), ('Saligrama', 'NNP'), ('', 'NN'), ('2015', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Rahman', 'NNP'), ('et', 'VBZ'), ('al', 'JJ'), ('', 'NNP'), ('', 'NN'), ('2018', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Mikolov', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('', 'NNP'), ('', 'NN'), ('2013', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Most', 'NNP'), ('works', 'VBZ'), ('focus', 'RB'), ('concept', 'JJ'), ('classiﬁca', 'NN'), ('tion', 'NN'), ('problem', 'NN'), ('', 'NNP'), ('Although', 'IN'), ('remains', 'VBZ'), ('challenging', 'VBG'), ('unsolved', 'JJ'), ('problem', 'NN'), ('', 'NN'), ('still', 'RB'), ('large', 'JJ'), ('gap', 'NN'), ('problem', 'NN'), ('setting', 'VBG'), ('realworld', 'JJ'), ('scenarios', 'NNS'), ('following', 'VBG'), ('aspects', 'NNS'), ('', 'NNP'), ('Firstly', 'NNP'), ('', 'NNP'), ('zeroshot', 'NNP'), ('learning', 'VBG'), ('benchmark', 'JJ'), ('datasets', 'NNS'), ('Welinder', 'NNP'), ('et', 'CC'), ('al', 'JJ'), ('', 'NNP'), ('', 'NN'), ('2010', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Nilsback', 'NNP'), ('Zisserman', 'NNP'), ('', 'NN'), ('2008', 'CD'), ('', 'NNP'), ('', 'NNP'), ('Russakovsky', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('', 'NNP'), ('', 'NN'), ('2015', 'CD'), ('', 'NN'), ('', 'NNP'), ('image', 'NN'), ('one', 'CD'), ('dominant', 'JJ'), ('object', 'JJ'), ('', 'NNP'), ('realworld', 'NN'), ('applications', 'NNS'), ('', 'VBP'), ('multiple', 'JJ'), ('objects', 'NNS'), ('may', 'MD'), ('appear', 'VB'), ('single', 'JJ'), ('image', 'NN'), ('', 'VBD'), ('Secondly', 'RB'), ('', 'JJ'), ('zeroshot', 'JJ'), ('classiﬁcation', 'NN'), ('methods', 'NNS'), ('based', 'VBN'), ('attributes', 'NNS'), ('semantic', 'JJ'), ('descriptions', 'NNS'), ('', 'VBP'), ('directly', 'RB'), ('applied', 'VBN'), ('zeroshot', 'JJ'), ('detection', 'NN'), ('entire', 'JJ'), ('scene', 'NN'), ('image', 'NN'), ('', 'VBZ'), ('Thirdly', 'RB'), ('', 'JJ'), ('setting', 'VBG'), ('zeroshot', 'NN'), ('learning', 'VBG'), ('consider', 'JJR'), ('occlusions', 'NNS'), ('clutter', 'NN'), ('', 'VBP'), ('commonly', 'RB'), ('exist', 'VBP'), ('realworld', 'NN'), ('applications', 'NNS'), ('', 'VBP'), ('To', 'TO'), ('close', 'VB'), ('gap', 'NN'), ('', 'NNP'), ('Rahman', 'NNP'), ('et', 'VBZ'), ('al', 'JJ'), ('', 'NNP'), ('', 'NN'), ('2018', 'CD'), ('', 'NN'), ('introduced', 'VBD'), ('new', 'JJ'), ('“', 'NNP'), ('zeroshot', 'NN'), ('object', 'NN'), ('detection', 'NN'), ('”', 'NNP'), ('', 'NNP'), ('ZSD', 'NNP'), ('', 'NNP'), ('problem', 'NN'), ('setting', 'VBG'), ('method', 'NN'), ('', 'NN'), ('aims', 'VBZ'), ('concurrently', 'RB'), ('detecting', 'VBG'), ('recognizing', 'VBG'), ('novel', 'JJ'), ('instance', 'NN'), ('absence', 'NN'), ('training', 'NN'), ('examples', 'NNS'), ('', 'VBP'), ('Although', 'IN'), ('datascarcity', 'NN'), ('challenge', 'NN'), ('exists', 'VBZ'), ('large', 'JJ'), ('num', 'JJ'), ('ber', 'NN'), ('categories', 'NNS'), ('realworld', 'VBP'), ('applications', 'NNS'), ('', 'VBP'), ('massive', 'JJ'), ('amount', 'NN'), ('textual', 'JJ'), ('data', 'NN'), ('categories', 'NNS'), ('', 'VBP'), ('These', 'DT'), ('data', 'NNS'), ('arrive', 'VBP'), ('form', 'NN'), ('dictionary', 'JJ'), ('entries', 'NNS'), ('', 'VBP'), ('online', 'JJ'), ('encyclopedias', 'FW'), ('online', 'JJ'), ('resources', 'NNS'), ('', 'VBP'), ('For', 'IN'), ('example', 'NN'), ('', 'NNP'), ('English', 'NNP'), ('Wikipedia', 'NNP'), ('5645010', 'CD'), ('articles', 'NNS'), ('site', 'NN'), ('', 'NNP'), ('provides', 'VBZ'), ('rich', 'JJ'), ('knowl', 'NN'), ('edge', 'NN'), ('base', 'NN'), ('different', 'JJ'), ('topics', 'NNS'), ('', 'VBP'), ('The', 'DT'), ('major', 'JJ'), ('problem', 'NN'), ('focus', 'NN'), ('paper', 'NN'), ('simultaneously', 'RB'), ('recognize', 'JJ'), ('locate', 'NN'), ('novel', 'NN'), ('object', 'NN'), ('instances', 'NNS'), ('using', 'VBG'), ('purely', 'RB'), ('unstructured', 'JJ'), ('textual', 'JJ'), ('descriptions', 'NNS'), ('train', 'VBP'), ('ing', 'VBG'), ('samples', 'NNS'), ('', 'VBP'), ('In', 'IN'), ('words', 'NNS'), ('', 'JJ'), ('goal', 'NN'), ('concurrently', 'RB'), ('link', 'VBP'), ('visual', 'JJ'), ('image', 'NN'), ('features', 'NNS'), ('semantic', 'JJ'), ('label', 'NN'), ('information', 'NN'), ('descriptions', 'NNS'), ('novel', 'VBP'), ('concepts', 'NNS'), ('presented', 'VBN'), ('form', 'JJ'), ('natural', 'JJ'), ('languages', 'NNS'), ('', 'VBP'), ('ie', 'JJ'), ('', 'NNP'), ('online', 'NN'), ('encyclopedias', 'NN'), ('', 'IN'), ('We', 'PRP'), ('de', 'VBP'), ('sign', 'FW'), ('novel', 'JJ'), ('deep', 'JJ'), ('learning', 'NN'), ('framework', 'NN'), ('zeroshot', 'JJ'), ('object', 'NN'), ('de', 'IN'), ('tection', 'NN'), ('textual', 'JJ'), ('description', 'NN'), ('', 'VBD'), ('The', 'DT'), ('proposed', 'VBN'), ('network', 'NN'), ('takes', 'VBZ'), ('description', 'NN'), ('image', 'NN'), ('input', 'NN'), ('outputs', 'VBZ'), ('afﬁnities', 'NNS'), ('description', 'NN'), ('object', 'VBP'), ('proposals', 'NNS'), ('im', 'VBP'), ('age', 'NN'), ('', 'NN'), ('We', 'PRP'), ('process', 'VBP'), ('textual', 'JJ'), ('description', 'NN'), ('wordbyword', 'NN'), ('fashion', 'NN'), ('wordLSTM', 'NN'), ('', 'NN'), ('For', 'IN'), ('word', 'NN'), ('description', 'NN'), ('', 'NNP'), ('achieve', 'VBP'), ('unitlevel', 'JJ'), ('attentions', 'NNS'), ('different', 'JJ'), ('units', 'NNS'), ('using', 'VBG'), ('LSTM', 'NNP'), ('', 'NNP'), ('Each', 'DT'), ('unit', 'NN'), ('determines', 'VBZ'), ('whether', 'IN'), ('speciﬁc', 'NN'), ('object', 'NN'), ('pattern', 'NN'), ('exists', 'VBZ'), ('object', 'VBP'), ('proposal', 'NN'), ('', 'IN'), ('The', 'DT'), ('contributions', 'NNS'), ('different', 'JJ'), ('units', 'NNS'), ('weighted', 'VBD'), ('visualunit', 'JJ'), ('attention', 'NN'), ('mechanism', 'NN'), ('', 'VBZ'), ('To', 'TO'), ('step', 'VB'), ('', 'NNP'), ('also', 'RB'), ('study', 'VBP'), ('wordlevel', 'JJ'), ('attention', 'NN'), ('learns', 'VBZ'), ('importance', 'JJ'), ('different', 'JJ'), ('words', 'NNS'), ('adaptive', 'JJ'), ('wordlevel', 'NN'), ('weighting', 'VBG'), ('', 'NN'), ('We', 'PRP'), ('achieve', 'VBP'), ('ﬁnal', 'JJ'), ('afﬁnity', 'NN'), ('averaging', 'VBG'), ('units', 'NNS'), ('’', 'VBP'), ('responses', 'NNS'), ('words', 'NNS'), ('', 'VBP'), ('We', 'PRP'), ('conduct', 'VBP'), ('experiments', 'NNS'), ('conﬁrm', 'VBP'), ('visual', 'JJ'), ('unitlevel', 'JJ'), ('attention', 'NN'), ('wordlevel', 'NN'), ('attention', 'NN'), ('contribute', 'NN'), ('good', 'JJ'), ('performance', 'NN'), ('proposed', 'VBN'), ('model', 'NN'), ('', 'NNS'), ('Compared', 'NNP'), ('related', 'VBD'), ('works', 'NNS'), ('literature', 'NN'), ('', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "exmpl_postagged = nltk.pos_tag(exmpl_filtered_sw)\n",
    "print(exmpl_postagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8392ea-fd4d-4101-980f-9e15fa17a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (ORGANIZATION ZeroShot/NNP)\n",
      "  (PERSON Object/NNP Detection/NNP Textual/NNP)\n",
      "  Descriptions/NNP\n",
      "  (PERSON Zhihui/NNP Li1/NNP)\n",
      "  /NNP\n",
      "  (PERSON Lina/NNP Yao1/NNP)\n",
      "  /NNP\n",
      "  (PERSON Xiaoqin/NNP Zhang2/NNP)\n",
      "  /NNP\n",
      "  (PERSON Xianzhi/NNP Wang3/NNP)\n",
      "  /NNP\n",
      "  (PERSON Salil/NNP Kanhere1/NNP)\n",
      "  /NNP\n",
      "  (PERSON Huaxiang/NNP)\n",
      "  Zhang4∗/NNP\n",
      "  1School/CD\n",
      "  (ORGANIZATION Computer/NNP Science/NNP)\n",
      "  Engineering/NNP\n",
      "  /NNP\n",
      "  (ORGANIZATION University/NNP New/NNP South/NNP)\n",
      "  Wales/NNP\n",
      "  2College/CD\n",
      "  Mathematics/NNPS\n",
      "  Information/NNP\n",
      "  Science/NNP\n",
      "  /NNP\n",
      "  (PERSON Wenzhou/NNP University/NNP)\n",
      "  3School/CD\n",
      "  Software/NNP\n",
      "  /NNP\n",
      "  (ORGANIZATION University/NNP Technology/NNP)\n",
      "  Sydney/NNP\n",
      "  4School/CD\n",
      "  Information/NNP\n",
      "  Science/NNP\n",
      "  Engineering/NNP\n",
      "  /NNP\n",
      "  Shandong/NNP\n",
      "  (PERSON Normal/NNP University/NNP Abstract/NNP Object/NNP)\n",
      "  detection/NN\n",
      "  important/JJ\n",
      "  realworld/NN\n",
      "  applications/NNS\n",
      "  /VBP\n",
      "  (PERSON Exist/NNP)\n",
      "  ing/VBG\n",
      "  methods/NNS\n",
      "  mainly/RB\n",
      "  focus/VBP\n",
      "  object/JJ\n",
      "  detection/NN\n",
      "  sufﬁcient/NN\n",
      "  labelled/VBD\n",
      "  training/NN\n",
      "  data/NNS\n",
      "  zeroshot/NN\n",
      "  object/JJ\n",
      "  detection/NN\n",
      "  concept/NN\n",
      "  names/NNS\n",
      "  /VBP\n",
      "  In/IN\n",
      "  paper/NN\n",
      "  /NN\n",
      "  address/NN\n",
      "  challenging/VBG\n",
      "  prob/JJ\n",
      "  lem/NN\n",
      "  zeroshot/NN\n",
      "  object/JJ\n",
      "  detection/NN\n",
      "  natural/JJ\n",
      "  language/NN\n",
      "  de/FW\n",
      "  scription/NN\n",
      "  /NN\n",
      "  aims/VBZ\n",
      "  simultaneously/RB\n",
      "  detect/JJ\n",
      "  recognize/NN\n",
      "  novel/NN\n",
      "  concept/NN\n",
      "  instances/NNS\n",
      "  textual/JJ\n",
      "  descriptions/NNS\n",
      "  /IN\n",
      "  We/PRP\n",
      "  propose/VBP\n",
      "  novel/JJ\n",
      "  deep/JJ\n",
      "  learning/NN\n",
      "  framework/NN\n",
      "  jointly/RB\n",
      "  learn/JJ\n",
      "  visual/JJ\n",
      "  units/NNS\n",
      "  /VBP\n",
      "  visualunit/JJ\n",
      "  attention/NN\n",
      "  wordlevel/NN\n",
      "  attention/NN\n",
      "  /NNP\n",
      "  com/NN\n",
      "  bined/VBD\n",
      "  achieve/JJ\n",
      "  wordproposal/NN\n",
      "  afﬁnity/NN\n",
      "  elementwise/NN\n",
      "  multiplication/NN\n",
      "  /NN\n",
      "  To/TO\n",
      "  best/VB\n",
      "  knowledge/NN\n",
      "  /NNP\n",
      "  ﬁrst/NNP\n",
      "  work/NN\n",
      "  zeroshot/NN\n",
      "  object/JJ\n",
      "  detection/NN\n",
      "  textual/JJ\n",
      "  descriptions/NNS\n",
      "  /VBP\n",
      "  Since/IN\n",
      "  directly/RB\n",
      "  related/VBN\n",
      "  work/NN\n",
      "  literature/NN\n",
      "  /JJ\n",
      "  investigate/NN\n",
      "  plausible/JJ\n",
      "  solutions/NNS\n",
      "  based/VBN\n",
      "  existing/VBG\n",
      "  zeroshot/JJ\n",
      "  ob/NN\n",
      "  ject/NN\n",
      "  detection/NN\n",
      "  fair/JJ\n",
      "  comparison/NN\n",
      "  /IN\n",
      "  We/PRP\n",
      "  conduct/VBP\n",
      "  extensive/JJ\n",
      "  experiments/NNS\n",
      "  three/CD\n",
      "  challenging/VBG\n",
      "  benchmark/NN\n",
      "  datasets/NNS\n",
      "  /VBP\n",
      "  The/DT\n",
      "  extensive/JJ\n",
      "  experimental/JJ\n",
      "  results/NNS\n",
      "  conﬁrm/VBP\n",
      "  superiority/NN\n",
      "  proposed/VBN\n",
      "  model/NN\n",
      "  /CD\n",
      "  Introduction/NNP\n",
      "  In/IN\n",
      "  last/JJ\n",
      "  decade/NN\n",
      "  /NN\n",
      "  researchers/NNS\n",
      "  made/VBD\n",
      "  promising/VBG\n",
      "  progress/NN\n",
      "  object/JJ\n",
      "  detection/NN\n",
      "  (PERSON Girshick/NNP)\n",
      "  /NN\n",
      "  2015/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Ren/NNP\n",
      "  et/FW\n",
      "  al/NN\n",
      "  /NNP\n",
      "  /NN\n",
      "  2015/CD\n",
      "  /NN\n",
      "  2017/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Lin/NNP\n",
      "  et/FW\n",
      "  al/NN\n",
      "  /NNP\n",
      "  /NN\n",
      "  2017/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Most/JJS\n",
      "  achievements/NNS\n",
      "  rely/VBP\n",
      "  collection/JJ\n",
      "  largescale/NN\n",
      "  labeled/VBD\n",
      "  training/NN\n",
      "  data/NNS\n",
      "  /NNP\n",
      "  Although/IN\n",
      "  searchers/NNS\n",
      "  struggled/VBD\n",
      "  acquire/VB\n",
      "  larger/JJR\n",
      "  datasets/NNS\n",
      "  broader/VBP\n",
      "  set/VBN\n",
      "  categories/NNS\n",
      "  /VBP\n",
      "  processing/VBG\n",
      "  procedure/NN\n",
      "  time/NN\n",
      "  consuming/VBG\n",
      "  tedious/JJ\n",
      "  /NNS\n",
      "  Furthermore/RB\n",
      "  /VBP\n",
      "  impossible/JJ\n",
      "  col/NN\n",
      "  lect/JJ\n",
      "  enough/RB\n",
      "  training/NN\n",
      "  data/NNS\n",
      "  rare/JJ\n",
      "  concepts/NNS\n",
      "  /VBP\n",
      "  ie/JJ\n",
      "  /NNP\n",
      "  (PERSON Okapia/NNP)\n",
      "  /NNP\n",
      "  There/EX\n",
      "  fore/RB\n",
      "  /JJ\n",
      "  challenging/VBG\n",
      "  problem/NN\n",
      "  simultaneously/RB\n",
      "  recog/VBZ\n",
      "  nize/JJ\n",
      "  locate/NN\n",
      "  novel/NN\n",
      "  object/JJ\n",
      "  instances/NNS\n",
      "  training/VBG\n",
      "  samples/NNS\n",
      "  /NNP\n",
      "  Zeroshot/NNP\n",
      "  learning/VBG\n",
      "  widely/RB\n",
      "  used/VBN\n",
      "  tackle/NN\n",
      "  problem/NN\n",
      "  data/NNS\n",
      "  scarcity/NN\n",
      "  (PERSON Akata/NNP)\n",
      "  et/CC\n",
      "  al/JJ\n",
      "  /NNP\n",
      "  /NN\n",
      "  2016/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Frome/NNP\n",
      "  et/FW\n",
      "  al/NN\n",
      "  /NNP\n",
      "  /NN\n",
      "  2013/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Lampert/NNP\n",
      "  et/FW\n",
      "  al/NN\n",
      "  /NNP\n",
      "  /NN\n",
      "  2009/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  (PERSON Zhang/NNP)\n",
      "  et/FW\n",
      "  al/NN\n",
      "  /NNP\n",
      "  /NN\n",
      "  2017/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  (PERSON Zhang/NNP Saligrama/NNP)\n",
      "  /NN\n",
      "  2015/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  (PERSON Rahman/NNP)\n",
      "  et/VBZ\n",
      "  al/JJ\n",
      "  /NNP\n",
      "  /NN\n",
      "  2018/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  (PERSON Mikolov/NNP)\n",
      "  et/FW\n",
      "  al/NN\n",
      "  /NNP\n",
      "  /NN\n",
      "  2013/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Most/NNP\n",
      "  works/VBZ\n",
      "  focus/RB\n",
      "  concept/JJ\n",
      "  classiﬁca/NN\n",
      "  tion/NN\n",
      "  problem/NN\n",
      "  /NNP\n",
      "  Although/IN\n",
      "  remains/VBZ\n",
      "  challenging/VBG\n",
      "  unsolved/JJ\n",
      "  problem/NN\n",
      "  /NN\n",
      "  still/RB\n",
      "  large/JJ\n",
      "  gap/NN\n",
      "  problem/NN\n",
      "  setting/VBG\n",
      "  realworld/JJ\n",
      "  scenarios/NNS\n",
      "  following/VBG\n",
      "  aspects/NNS\n",
      "  /NNP\n",
      "  Firstly/NNP\n",
      "  /NNP\n",
      "  zeroshot/NNP\n",
      "  learning/VBG\n",
      "  benchmark/JJ\n",
      "  datasets/NNS\n",
      "  Welinder/NNP\n",
      "  et/CC\n",
      "  al/JJ\n",
      "  /NNP\n",
      "  /NN\n",
      "  2010/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Nilsback/NNP\n",
      "  Zisserman/NNP\n",
      "  /NN\n",
      "  2008/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Russakovsky/NNP\n",
      "  et/FW\n",
      "  al/NN\n",
      "  /NNP\n",
      "  /NN\n",
      "  2015/CD\n",
      "  /NN\n",
      "  /NNP\n",
      "  image/NN\n",
      "  one/CD\n",
      "  dominant/JJ\n",
      "  object/JJ\n",
      "  /NNP\n",
      "  realworld/NN\n",
      "  applications/NNS\n",
      "  /VBP\n",
      "  multiple/JJ\n",
      "  objects/NNS\n",
      "  may/MD\n",
      "  appear/VB\n",
      "  single/JJ\n",
      "  image/NN\n",
      "  /VBD\n",
      "  Secondly/RB\n",
      "  /JJ\n",
      "  zeroshot/JJ\n",
      "  classiﬁcation/NN\n",
      "  methods/NNS\n",
      "  based/VBN\n",
      "  attributes/NNS\n",
      "  semantic/JJ\n",
      "  descriptions/NNS\n",
      "  /VBP\n",
      "  directly/RB\n",
      "  applied/VBN\n",
      "  zeroshot/JJ\n",
      "  detection/NN\n",
      "  entire/JJ\n",
      "  scene/NN\n",
      "  image/NN\n",
      "  /VBZ\n",
      "  Thirdly/RB\n",
      "  /JJ\n",
      "  setting/VBG\n",
      "  zeroshot/NN\n",
      "  learning/VBG\n",
      "  consider/JJR\n",
      "  occlusions/NNS\n",
      "  clutter/NN\n",
      "  /VBP\n",
      "  commonly/RB\n",
      "  exist/VBP\n",
      "  realworld/NN\n",
      "  applications/NNS\n",
      "  /VBP\n",
      "  To/TO\n",
      "  close/VB\n",
      "  gap/NN\n",
      "  /NNP\n",
      "  (PERSON Rahman/NNP)\n",
      "  et/VBZ\n",
      "  al/JJ\n",
      "  /NNP\n",
      "  /NN\n",
      "  2018/CD\n",
      "  /NN\n",
      "  introduced/VBD\n",
      "  new/JJ\n",
      "  “/NNP\n",
      "  zeroshot/NN\n",
      "  object/NN\n",
      "  detection/NN\n",
      "  ”/NNP\n",
      "  /NNP\n",
      "  ZSD/NNP\n",
      "  /NNP\n",
      "  problem/NN\n",
      "  setting/VBG\n",
      "  method/NN\n",
      "  /NN\n",
      "  aims/VBZ\n",
      "  concurrently/RB\n",
      "  detecting/VBG\n",
      "  recognizing/VBG\n",
      "  novel/JJ\n",
      "  instance/NN\n",
      "  absence/NN\n",
      "  training/NN\n",
      "  examples/NNS\n",
      "  /VBP\n",
      "  Although/IN\n",
      "  datascarcity/NN\n",
      "  challenge/NN\n",
      "  exists/VBZ\n",
      "  large/JJ\n",
      "  num/JJ\n",
      "  ber/NN\n",
      "  categories/NNS\n",
      "  realworld/VBP\n",
      "  applications/NNS\n",
      "  /VBP\n",
      "  massive/JJ\n",
      "  amount/NN\n",
      "  textual/JJ\n",
      "  data/NN\n",
      "  categories/NNS\n",
      "  /VBP\n",
      "  These/DT\n",
      "  data/NNS\n",
      "  arrive/VBP\n",
      "  form/NN\n",
      "  dictionary/JJ\n",
      "  entries/NNS\n",
      "  /VBP\n",
      "  online/JJ\n",
      "  encyclopedias/FW\n",
      "  online/JJ\n",
      "  resources/NNS\n",
      "  /VBP\n",
      "  For/IN\n",
      "  example/NN\n",
      "  /NNP\n",
      "  English/NNP\n",
      "  Wikipedia/NNP\n",
      "  5645010/CD\n",
      "  articles/NNS\n",
      "  site/NN\n",
      "  /NNP\n",
      "  provides/VBZ\n",
      "  rich/JJ\n",
      "  knowl/NN\n",
      "  edge/NN\n",
      "  base/NN\n",
      "  different/JJ\n",
      "  topics/NNS\n",
      "  /VBP\n",
      "  The/DT\n",
      "  major/JJ\n",
      "  problem/NN\n",
      "  focus/NN\n",
      "  paper/NN\n",
      "  simultaneously/RB\n",
      "  recognize/JJ\n",
      "  locate/NN\n",
      "  novel/NN\n",
      "  object/NN\n",
      "  instances/NNS\n",
      "  using/VBG\n",
      "  purely/RB\n",
      "  unstructured/JJ\n",
      "  textual/JJ\n",
      "  descriptions/NNS\n",
      "  train/VBP\n",
      "  ing/VBG\n",
      "  samples/NNS\n",
      "  /VBP\n",
      "  In/IN\n",
      "  words/NNS\n",
      "  /JJ\n",
      "  goal/NN\n",
      "  concurrently/RB\n",
      "  link/VBP\n",
      "  visual/JJ\n",
      "  image/NN\n",
      "  features/NNS\n",
      "  semantic/JJ\n",
      "  label/NN\n",
      "  information/NN\n",
      "  descriptions/NNS\n",
      "  novel/VBP\n",
      "  concepts/NNS\n",
      "  presented/VBN\n",
      "  form/JJ\n",
      "  natural/JJ\n",
      "  languages/NNS\n",
      "  /VBP\n",
      "  ie/JJ\n",
      "  /NNP\n",
      "  online/NN\n",
      "  encyclopedias/NN\n",
      "  /IN\n",
      "  We/PRP\n",
      "  de/VBP\n",
      "  sign/FW\n",
      "  novel/JJ\n",
      "  deep/JJ\n",
      "  learning/NN\n",
      "  framework/NN\n",
      "  zeroshot/JJ\n",
      "  object/NN\n",
      "  de/IN\n",
      "  tection/NN\n",
      "  textual/JJ\n",
      "  description/NN\n",
      "  /VBD\n",
      "  The/DT\n",
      "  proposed/VBN\n",
      "  network/NN\n",
      "  takes/VBZ\n",
      "  description/NN\n",
      "  image/NN\n",
      "  input/NN\n",
      "  outputs/VBZ\n",
      "  afﬁnities/NNS\n",
      "  description/NN\n",
      "  object/VBP\n",
      "  proposals/NNS\n",
      "  im/VBP\n",
      "  age/NN\n",
      "  /NN\n",
      "  We/PRP\n",
      "  process/VBP\n",
      "  textual/JJ\n",
      "  description/NN\n",
      "  wordbyword/NN\n",
      "  fashion/NN\n",
      "  (ORGANIZATION wordLSTM/NN)\n",
      "  /NN\n",
      "  For/IN\n",
      "  word/NN\n",
      "  description/NN\n",
      "  /NNP\n",
      "  achieve/VBP\n",
      "  unitlevel/JJ\n",
      "  attentions/NNS\n",
      "  different/JJ\n",
      "  units/NNS\n",
      "  using/VBG\n",
      "  (ORGANIZATION LSTM/NNP)\n",
      "  /NNP\n",
      "  Each/DT\n",
      "  unit/NN\n",
      "  determines/VBZ\n",
      "  whether/IN\n",
      "  speciﬁc/NN\n",
      "  object/NN\n",
      "  pattern/NN\n",
      "  exists/VBZ\n",
      "  object/VBP\n",
      "  proposal/NN\n",
      "  /IN\n",
      "  The/DT\n",
      "  contributions/NNS\n",
      "  different/JJ\n",
      "  units/NNS\n",
      "  weighted/VBD\n",
      "  visualunit/JJ\n",
      "  attention/NN\n",
      "  mechanism/NN\n",
      "  /VBZ\n",
      "  To/TO\n",
      "  step/VB\n",
      "  /NNP\n",
      "  also/RB\n",
      "  study/VBP\n",
      "  wordlevel/JJ\n",
      "  attention/NN\n",
      "  learns/VBZ\n",
      "  importance/JJ\n",
      "  different/JJ\n",
      "  words/NNS\n",
      "  adaptive/JJ\n",
      "  wordlevel/NN\n",
      "  weighting/VBG\n",
      "  /NN\n",
      "  We/PRP\n",
      "  achieve/VBP\n",
      "  ﬁnal/JJ\n",
      "  afﬁnity/NN\n",
      "  averaging/VBG\n",
      "  units/NNS\n",
      "  ’/VBP\n",
      "  responses/NNS\n",
      "  words/NNS\n",
      "  /VBP\n",
      "  We/PRP\n",
      "  conduct/VBP\n",
      "  experiments/NNS\n",
      "  conﬁrm/VBP\n",
      "  visual/JJ\n",
      "  unitlevel/JJ\n",
      "  attention/NN\n",
      "  wordlevel/NN\n",
      "  attention/NN\n",
      "  contribute/NN\n",
      "  good/JJ\n",
      "  performance/NN\n",
      "  proposed/VBN\n",
      "  model/NN\n",
      "  /NNS\n",
      "  (ORGANIZATION Compared/NNP)\n",
      "  related/VBD\n",
      "  works/NNS\n",
      "  literature/NN\n",
      "  /NN)\n"
     ]
    }
   ],
   "source": [
    "exmpl_chunks = nltk.ne_chunk(exmpl_postagged)\n",
    "print(exmpl_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b599b50-683e-46fa-973e-57bb45fb8c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  ZeroShot/NNP\n",
      "  Object/NNP\n",
      "  Detection/NNP\n",
      "  Textual/NNP\n",
      "  Descriptions/NNP\n",
      "  Zhihui/NNP\n",
      "  Li1/NNP\n",
      "  /NNP\n",
      "  Lina/NNP\n",
      "  Yao1/NNP\n",
      "  /NNP\n",
      "  Xiaoqin/NNP\n",
      "  Zhang2/NNP\n",
      "  /NNP\n",
      "  Xianzhi/NNP\n",
      "  Wang3/NNP\n",
      "  /NNP\n",
      "  Salil/NNP\n",
      "  Kanhere1/NNP\n",
      "  /NNP\n",
      "  Huaxiang/NNP\n",
      "  Zhang4∗/NNP\n",
      "  1School/CD\n",
      "  Computer/NNP\n",
      "  Science/NNP\n",
      "  Engineering/NNP\n",
      "  /NNP\n",
      "  University/NNP\n",
      "  New/NNP\n",
      "  South/NNP\n",
      "  Wales/NNP\n",
      "  2College/CD\n",
      "  Mathematics/NNPS\n",
      "  Information/NNP\n",
      "  Science/NNP\n",
      "  /NNP\n",
      "  Wenzhou/NNP\n",
      "  University/NNP\n",
      "  3School/CD\n",
      "  Software/NNP\n",
      "  /NNP\n",
      "  University/NNP\n",
      "  Technology/NNP\n",
      "  Sydney/NNP\n",
      "  4School/CD\n",
      "  Information/NNP\n",
      "  Science/NNP\n",
      "  Engineering/NNP\n",
      "  /NNP\n",
      "  Shandong/NNP\n",
      "  Normal/NNP\n",
      "  University/NNP\n",
      "  Abstract/NNP\n",
      "  Object/NNP\n",
      "  (NP detection/NN)\n",
      "  (NP important/JJ realworld/NN)\n",
      "  applications/NNS\n",
      "  /VBP\n",
      "  Exist/NNP\n",
      "  ing/VBG\n",
      "  methods/NNS\n",
      "  mainly/RB\n",
      "  focus/VBP\n",
      "  (NP object/JJ detection/NN)\n",
      "  (NP sufﬁcient/NN)\n",
      "  labelled/VBD\n",
      "  (NP training/NN)\n",
      "  data/NNS\n",
      "  (NP zeroshot/NN)\n",
      "  (NP object/JJ detection/NN)\n",
      "  (NP concept/NN)\n",
      "  names/NNS\n",
      "  /VBP\n",
      "  In/IN\n",
      "  (NP paper/NN)\n",
      "  (NP /NN)\n",
      "  (NP address/NN)\n",
      "  challenging/VBG\n",
      "  (NP prob/JJ lem/NN)\n",
      "  (NP zeroshot/NN)\n",
      "  (NP object/JJ detection/NN)\n",
      "  (NP natural/JJ language/NN)\n",
      "  de/FW\n",
      "  (NP scription/NN)\n",
      "  (NP /NN)\n",
      "  aims/VBZ\n",
      "  simultaneously/RB\n",
      "  (NP detect/JJ recognize/NN)\n",
      "  (NP novel/NN)\n",
      "  (NP concept/NN)\n",
      "  instances/NNS\n",
      "  textual/JJ\n",
      "  descriptions/NNS\n",
      "  /IN\n",
      "  We/PRP\n",
      "  propose/VBP\n",
      "  (NP novel/JJ deep/JJ learning/NN)\n",
      "  (NP framework/NN)\n",
      "  jointly/RB\n",
      "  learn/JJ\n",
      "  visual/JJ\n",
      "  units/NNS\n",
      "  /VBP\n",
      "  (NP visualunit/JJ attention/NN)\n",
      "  (NP wordlevel/NN)\n",
      "  (NP attention/NN)\n",
      "  /NNP\n",
      "  (NP com/NN)\n",
      "  bined/VBD\n",
      "  (NP achieve/JJ wordproposal/NN)\n",
      "  (NP afﬁnity/NN)\n",
      "  (NP elementwise/NN)\n",
      "  (NP multiplication/NN)\n",
      "  (NP /NN)\n",
      "  To/TO\n",
      "  best/VB\n",
      "  (NP knowledge/NN)\n",
      "  /NNP\n",
      "  ﬁrst/NNP\n",
      "  (NP work/NN)\n",
      "  (NP zeroshot/NN)\n",
      "  (NP object/JJ detection/NN)\n",
      "  textual/JJ\n",
      "  descriptions/NNS\n",
      "  /VBP\n",
      "  Since/IN\n",
      "  directly/RB\n",
      "  related/VBN\n",
      "  (NP work/NN)\n",
      "  (NP literature/NN)\n",
      "  (NP /JJ investigate/NN)\n",
      "  plausible/JJ\n",
      "  solutions/NNS\n",
      "  based/VBN\n",
      "  existing/VBG\n",
      "  (NP zeroshot/JJ ob/NN)\n",
      "  (NP ject/NN)\n",
      "  (NP detection/NN)\n",
      "  (NP fair/JJ comparison/NN)\n",
      "  /IN\n",
      "  We/PRP\n",
      "  conduct/VBP\n",
      "  extensive/JJ\n",
      "  experiments/NNS\n",
      "  three/CD\n",
      "  challenging/VBG\n",
      "  (NP benchmark/NN)\n",
      "  datasets/NNS\n",
      "  /VBP\n",
      "  The/DT\n",
      "  extensive/JJ\n",
      "  experimental/JJ\n",
      "  results/NNS\n",
      "  conﬁrm/VBP\n",
      "  (NP superiority/NN)\n",
      "  proposed/VBN\n",
      "  (NP model/NN)\n",
      "  /CD\n",
      "  Introduction/NNP\n",
      "  In/IN\n",
      "  (NP last/JJ decade/NN)\n",
      "  (NP /NN)\n",
      "  researchers/NNS\n",
      "  made/VBD\n",
      "  promising/VBG\n",
      "  (NP progress/NN)\n",
      "  (NP object/JJ detection/NN)\n",
      "  Girshick/NNP\n",
      "  (NP /NN)\n",
      "  2015/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Ren/NNP\n",
      "  et/FW\n",
      "  (NP al/NN)\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2015/CD\n",
      "  (NP /NN)\n",
      "  2017/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Lin/NNP\n",
      "  et/FW\n",
      "  (NP al/NN)\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2017/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Most/JJS\n",
      "  achievements/NNS\n",
      "  rely/VBP\n",
      "  (NP collection/JJ largescale/NN)\n",
      "  labeled/VBD\n",
      "  (NP training/NN)\n",
      "  data/NNS\n",
      "  /NNP\n",
      "  Although/IN\n",
      "  searchers/NNS\n",
      "  struggled/VBD\n",
      "  acquire/VB\n",
      "  larger/JJR\n",
      "  datasets/NNS\n",
      "  broader/VBP\n",
      "  set/VBN\n",
      "  categories/NNS\n",
      "  /VBP\n",
      "  processing/VBG\n",
      "  (NP procedure/NN)\n",
      "  (NP time/NN)\n",
      "  consuming/VBG\n",
      "  tedious/JJ\n",
      "  /NNS\n",
      "  Furthermore/RB\n",
      "  /VBP\n",
      "  (NP impossible/JJ col/NN)\n",
      "  lect/JJ\n",
      "  enough/RB\n",
      "  (NP training/NN)\n",
      "  data/NNS\n",
      "  rare/JJ\n",
      "  concepts/NNS\n",
      "  /VBP\n",
      "  ie/JJ\n",
      "  /NNP\n",
      "  Okapia/NNP\n",
      "  /NNP\n",
      "  There/EX\n",
      "  fore/RB\n",
      "  /JJ\n",
      "  challenging/VBG\n",
      "  (NP problem/NN)\n",
      "  simultaneously/RB\n",
      "  recog/VBZ\n",
      "  (NP nize/JJ locate/NN)\n",
      "  (NP novel/NN)\n",
      "  object/JJ\n",
      "  instances/NNS\n",
      "  training/VBG\n",
      "  samples/NNS\n",
      "  /NNP\n",
      "  Zeroshot/NNP\n",
      "  learning/VBG\n",
      "  widely/RB\n",
      "  used/VBN\n",
      "  (NP tackle/NN)\n",
      "  (NP problem/NN)\n",
      "  data/NNS\n",
      "  (NP scarcity/NN)\n",
      "  Akata/NNP\n",
      "  et/CC\n",
      "  al/JJ\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2016/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Frome/NNP\n",
      "  et/FW\n",
      "  (NP al/NN)\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2013/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Lampert/NNP\n",
      "  et/FW\n",
      "  (NP al/NN)\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2009/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Zhang/NNP\n",
      "  et/FW\n",
      "  (NP al/NN)\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2017/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Zhang/NNP\n",
      "  Saligrama/NNP\n",
      "  (NP /NN)\n",
      "  2015/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Rahman/NNP\n",
      "  et/VBZ\n",
      "  al/JJ\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2018/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Mikolov/NNP\n",
      "  et/FW\n",
      "  (NP al/NN)\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2013/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Most/NNP\n",
      "  works/VBZ\n",
      "  focus/RB\n",
      "  (NP concept/JJ classiﬁca/NN)\n",
      "  (NP tion/NN)\n",
      "  (NP problem/NN)\n",
      "  /NNP\n",
      "  Although/IN\n",
      "  remains/VBZ\n",
      "  challenging/VBG\n",
      "  (NP unsolved/JJ problem/NN)\n",
      "  (NP /NN)\n",
      "  still/RB\n",
      "  (NP large/JJ gap/NN)\n",
      "  (NP problem/NN)\n",
      "  setting/VBG\n",
      "  realworld/JJ\n",
      "  scenarios/NNS\n",
      "  following/VBG\n",
      "  aspects/NNS\n",
      "  /NNP\n",
      "  Firstly/NNP\n",
      "  /NNP\n",
      "  zeroshot/NNP\n",
      "  learning/VBG\n",
      "  benchmark/JJ\n",
      "  datasets/NNS\n",
      "  Welinder/NNP\n",
      "  et/CC\n",
      "  al/JJ\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2010/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Nilsback/NNP\n",
      "  Zisserman/NNP\n",
      "  (NP /NN)\n",
      "  2008/CD\n",
      "  /NNP\n",
      "  /NNP\n",
      "  Russakovsky/NNP\n",
      "  et/FW\n",
      "  (NP al/NN)\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2015/CD\n",
      "  (NP /NN)\n",
      "  /NNP\n",
      "  (NP image/NN)\n",
      "  one/CD\n",
      "  dominant/JJ\n",
      "  object/JJ\n",
      "  /NNP\n",
      "  (NP realworld/NN)\n",
      "  applications/NNS\n",
      "  /VBP\n",
      "  multiple/JJ\n",
      "  objects/NNS\n",
      "  may/MD\n",
      "  appear/VB\n",
      "  (NP single/JJ image/NN)\n",
      "  /VBD\n",
      "  Secondly/RB\n",
      "  (NP /JJ zeroshot/JJ classiﬁcation/NN)\n",
      "  methods/NNS\n",
      "  based/VBN\n",
      "  attributes/NNS\n",
      "  semantic/JJ\n",
      "  descriptions/NNS\n",
      "  /VBP\n",
      "  directly/RB\n",
      "  applied/VBN\n",
      "  (NP zeroshot/JJ detection/NN)\n",
      "  (NP entire/JJ scene/NN)\n",
      "  (NP image/NN)\n",
      "  /VBZ\n",
      "  Thirdly/RB\n",
      "  /JJ\n",
      "  setting/VBG\n",
      "  (NP zeroshot/NN)\n",
      "  learning/VBG\n",
      "  consider/JJR\n",
      "  occlusions/NNS\n",
      "  (NP clutter/NN)\n",
      "  /VBP\n",
      "  commonly/RB\n",
      "  exist/VBP\n",
      "  (NP realworld/NN)\n",
      "  applications/NNS\n",
      "  /VBP\n",
      "  To/TO\n",
      "  close/VB\n",
      "  (NP gap/NN)\n",
      "  /NNP\n",
      "  Rahman/NNP\n",
      "  et/VBZ\n",
      "  al/JJ\n",
      "  /NNP\n",
      "  (NP /NN)\n",
      "  2018/CD\n",
      "  (NP /NN)\n",
      "  introduced/VBD\n",
      "  new/JJ\n",
      "  “/NNP\n",
      "  (NP zeroshot/NN)\n",
      "  (NP object/NN)\n",
      "  (NP detection/NN)\n",
      "  ”/NNP\n",
      "  /NNP\n",
      "  ZSD/NNP\n",
      "  /NNP\n",
      "  (NP problem/NN)\n",
      "  setting/VBG\n",
      "  (NP method/NN)\n",
      "  (NP /NN)\n",
      "  aims/VBZ\n",
      "  concurrently/RB\n",
      "  detecting/VBG\n",
      "  recognizing/VBG\n",
      "  (NP novel/JJ instance/NN)\n",
      "  (NP absence/NN)\n",
      "  (NP training/NN)\n",
      "  examples/NNS\n",
      "  /VBP\n",
      "  Although/IN\n",
      "  (NP datascarcity/NN)\n",
      "  (NP challenge/NN)\n",
      "  exists/VBZ\n",
      "  (NP large/JJ num/JJ ber/NN)\n",
      "  categories/NNS\n",
      "  realworld/VBP\n",
      "  applications/NNS\n",
      "  /VBP\n",
      "  (NP massive/JJ amount/NN)\n",
      "  (NP textual/JJ data/NN)\n",
      "  categories/NNS\n",
      "  /VBP\n",
      "  These/DT\n",
      "  data/NNS\n",
      "  arrive/VBP\n",
      "  (NP form/NN)\n",
      "  dictionary/JJ\n",
      "  entries/NNS\n",
      "  /VBP\n",
      "  online/JJ\n",
      "  encyclopedias/FW\n",
      "  online/JJ\n",
      "  resources/NNS\n",
      "  /VBP\n",
      "  For/IN\n",
      "  (NP example/NN)\n",
      "  /NNP\n",
      "  English/NNP\n",
      "  Wikipedia/NNP\n",
      "  5645010/CD\n",
      "  articles/NNS\n",
      "  (NP site/NN)\n",
      "  /NNP\n",
      "  provides/VBZ\n",
      "  (NP rich/JJ knowl/NN)\n",
      "  (NP edge/NN)\n",
      "  (NP base/NN)\n",
      "  different/JJ\n",
      "  topics/NNS\n",
      "  /VBP\n",
      "  (NP The/DT major/JJ problem/NN)\n",
      "  (NP focus/NN)\n",
      "  (NP paper/NN)\n",
      "  simultaneously/RB\n",
      "  (NP recognize/JJ locate/NN)\n",
      "  (NP novel/NN)\n",
      "  (NP object/NN)\n",
      "  instances/NNS\n",
      "  using/VBG\n",
      "  purely/RB\n",
      "  unstructured/JJ\n",
      "  textual/JJ\n",
      "  descriptions/NNS\n",
      "  train/VBP\n",
      "  ing/VBG\n",
      "  samples/NNS\n",
      "  /VBP\n",
      "  In/IN\n",
      "  words/NNS\n",
      "  (NP /JJ goal/NN)\n",
      "  concurrently/RB\n",
      "  link/VBP\n",
      "  (NP visual/JJ image/NN)\n",
      "  features/NNS\n",
      "  (NP semantic/JJ label/NN)\n",
      "  (NP information/NN)\n",
      "  descriptions/NNS\n",
      "  novel/VBP\n",
      "  concepts/NNS\n",
      "  presented/VBN\n",
      "  form/JJ\n",
      "  natural/JJ\n",
      "  languages/NNS\n",
      "  /VBP\n",
      "  ie/JJ\n",
      "  /NNP\n",
      "  (NP online/NN)\n",
      "  (NP encyclopedias/NN)\n",
      "  /IN\n",
      "  We/PRP\n",
      "  de/VBP\n",
      "  sign/FW\n",
      "  (NP novel/JJ deep/JJ learning/NN)\n",
      "  (NP framework/NN)\n",
      "  (NP zeroshot/JJ object/NN)\n",
      "  de/IN\n",
      "  (NP tection/NN)\n",
      "  (NP textual/JJ description/NN)\n",
      "  /VBD\n",
      "  The/DT\n",
      "  proposed/VBN\n",
      "  (NP network/NN)\n",
      "  takes/VBZ\n",
      "  (NP description/NN)\n",
      "  (NP image/NN)\n",
      "  (NP input/NN)\n",
      "  outputs/VBZ\n",
      "  afﬁnities/NNS\n",
      "  (NP description/NN)\n",
      "  object/VBP\n",
      "  proposals/NNS\n",
      "  im/VBP\n",
      "  (NP age/NN)\n",
      "  (NP /NN)\n",
      "  We/PRP\n",
      "  process/VBP\n",
      "  (NP textual/JJ description/NN)\n",
      "  (NP wordbyword/NN)\n",
      "  (NP fashion/NN)\n",
      "  (NP wordLSTM/NN)\n",
      "  (NP /NN)\n",
      "  For/IN\n",
      "  (NP word/NN)\n",
      "  (NP description/NN)\n",
      "  /NNP\n",
      "  achieve/VBP\n",
      "  unitlevel/JJ\n",
      "  attentions/NNS\n",
      "  different/JJ\n",
      "  units/NNS\n",
      "  using/VBG\n",
      "  LSTM/NNP\n",
      "  /NNP\n",
      "  (NP Each/DT unit/NN)\n",
      "  determines/VBZ\n",
      "  whether/IN\n",
      "  (NP speciﬁc/NN)\n",
      "  (NP object/NN)\n",
      "  (NP pattern/NN)\n",
      "  exists/VBZ\n",
      "  object/VBP\n",
      "  (NP proposal/NN)\n",
      "  /IN\n",
      "  The/DT\n",
      "  contributions/NNS\n",
      "  different/JJ\n",
      "  units/NNS\n",
      "  weighted/VBD\n",
      "  (NP visualunit/JJ attention/NN)\n",
      "  (NP mechanism/NN)\n",
      "  /VBZ\n",
      "  To/TO\n",
      "  step/VB\n",
      "  /NNP\n",
      "  also/RB\n",
      "  study/VBP\n",
      "  (NP wordlevel/JJ attention/NN)\n",
      "  learns/VBZ\n",
      "  importance/JJ\n",
      "  different/JJ\n",
      "  words/NNS\n",
      "  (NP adaptive/JJ wordlevel/NN)\n",
      "  weighting/VBG\n",
      "  (NP /NN)\n",
      "  We/PRP\n",
      "  achieve/VBP\n",
      "  (NP ﬁnal/JJ afﬁnity/NN)\n",
      "  averaging/VBG\n",
      "  units/NNS\n",
      "  ’/VBP\n",
      "  responses/NNS\n",
      "  words/NNS\n",
      "  /VBP\n",
      "  We/PRP\n",
      "  conduct/VBP\n",
      "  experiments/NNS\n",
      "  conﬁrm/VBP\n",
      "  (NP visual/JJ unitlevel/JJ attention/NN)\n",
      "  (NP wordlevel/NN)\n",
      "  (NP attention/NN)\n",
      "  (NP contribute/NN)\n",
      "  (NP good/JJ performance/NN)\n",
      "  proposed/VBN\n",
      "  (NP model/NN)\n",
      "  /NNS\n",
      "  Compared/NNP\n",
      "  related/VBD\n",
      "  works/NNS\n",
      "  (NP literature/NN)\n",
      "  (NP /NN))\n"
     ]
    }
   ],
   "source": [
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(exmpl_postagged)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824ef0f3-b7ad-4aee-9d4a-fd61282884bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ZeroShot', 'NNP', 'O'),\n",
      " ('Object', 'NNP', 'O'),\n",
      " ('Detection', 'NNP', 'O'),\n",
      " ('Textual', 'NNP', 'O'),\n",
      " ('Descriptions', 'NNP', 'O'),\n",
      " ('Zhihui', 'NNP', 'O'),\n",
      " ('Li1', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Lina', 'NNP', 'O'),\n",
      " ('Yao1', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Xiaoqin', 'NNP', 'O'),\n",
      " ('Zhang2', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Xianzhi', 'NNP', 'O'),\n",
      " ('Wang3', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Salil', 'NNP', 'O'),\n",
      " ('Kanhere1', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Huaxiang', 'NNP', 'O'),\n",
      " ('Zhang4∗', 'NNP', 'O'),\n",
      " ('1School', 'CD', 'O'),\n",
      " ('Computer', 'NNP', 'O'),\n",
      " ('Science', 'NNP', 'O'),\n",
      " ('Engineering', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('University', 'NNP', 'O'),\n",
      " ('New', 'NNP', 'O'),\n",
      " ('South', 'NNP', 'O'),\n",
      " ('Wales', 'NNP', 'O'),\n",
      " ('2College', 'CD', 'O'),\n",
      " ('Mathematics', 'NNPS', 'O'),\n",
      " ('Information', 'NNP', 'O'),\n",
      " ('Science', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Wenzhou', 'NNP', 'O'),\n",
      " ('University', 'NNP', 'O'),\n",
      " ('3School', 'CD', 'O'),\n",
      " ('Software', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('University', 'NNP', 'O'),\n",
      " ('Technology', 'NNP', 'O'),\n",
      " ('Sydney', 'NNP', 'O'),\n",
      " ('4School', 'CD', 'O'),\n",
      " ('Information', 'NNP', 'O'),\n",
      " ('Science', 'NNP', 'O'),\n",
      " ('Engineering', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Shandong', 'NNP', 'O'),\n",
      " ('Normal', 'NNP', 'O'),\n",
      " ('University', 'NNP', 'O'),\n",
      " ('Abstract', 'NNP', 'O'),\n",
      " ('Object', 'NNP', 'O'),\n",
      " ('detection', 'NN', 'B-NP'),\n",
      " ('important', 'JJ', 'B-NP'),\n",
      " ('realworld', 'NN', 'I-NP'),\n",
      " ('applications', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('Exist', 'NNP', 'O'),\n",
      " ('ing', 'VBG', 'O'),\n",
      " ('methods', 'NNS', 'O'),\n",
      " ('mainly', 'RB', 'O'),\n",
      " ('focus', 'VBP', 'O'),\n",
      " ('object', 'JJ', 'B-NP'),\n",
      " ('detection', 'NN', 'I-NP'),\n",
      " ('sufﬁcient', 'NN', 'B-NP'),\n",
      " ('labelled', 'VBD', 'O'),\n",
      " ('training', 'NN', 'B-NP'),\n",
      " ('data', 'NNS', 'O'),\n",
      " ('zeroshot', 'NN', 'B-NP'),\n",
      " ('object', 'JJ', 'B-NP'),\n",
      " ('detection', 'NN', 'I-NP'),\n",
      " ('concept', 'NN', 'B-NP'),\n",
      " ('names', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('In', 'IN', 'O'),\n",
      " ('paper', 'NN', 'B-NP'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('address', 'NN', 'B-NP'),\n",
      " ('challenging', 'VBG', 'O'),\n",
      " ('prob', 'JJ', 'B-NP'),\n",
      " ('lem', 'NN', 'I-NP'),\n",
      " ('zeroshot', 'NN', 'B-NP'),\n",
      " ('object', 'JJ', 'B-NP'),\n",
      " ('detection', 'NN', 'I-NP'),\n",
      " ('natural', 'JJ', 'B-NP'),\n",
      " ('language', 'NN', 'I-NP'),\n",
      " ('de', 'FW', 'O'),\n",
      " ('scription', 'NN', 'B-NP'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('aims', 'VBZ', 'O'),\n",
      " ('simultaneously', 'RB', 'O'),\n",
      " ('detect', 'JJ', 'B-NP'),\n",
      " ('recognize', 'NN', 'I-NP'),\n",
      " ('novel', 'NN', 'B-NP'),\n",
      " ('concept', 'NN', 'B-NP'),\n",
      " ('instances', 'NNS', 'O'),\n",
      " ('textual', 'JJ', 'O'),\n",
      " ('descriptions', 'NNS', 'O'),\n",
      " ('', 'IN', 'O'),\n",
      " ('We', 'PRP', 'O'),\n",
      " ('propose', 'VBP', 'O'),\n",
      " ('novel', 'JJ', 'B-NP'),\n",
      " ('deep', 'JJ', 'I-NP'),\n",
      " ('learning', 'NN', 'I-NP'),\n",
      " ('framework', 'NN', 'B-NP'),\n",
      " ('jointly', 'RB', 'O'),\n",
      " ('learn', 'JJ', 'O'),\n",
      " ('visual', 'JJ', 'O'),\n",
      " ('units', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('visualunit', 'JJ', 'B-NP'),\n",
      " ('attention', 'NN', 'I-NP'),\n",
      " ('wordlevel', 'NN', 'B-NP'),\n",
      " ('attention', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('com', 'NN', 'B-NP'),\n",
      " ('bined', 'VBD', 'O'),\n",
      " ('achieve', 'JJ', 'B-NP'),\n",
      " ('wordproposal', 'NN', 'I-NP'),\n",
      " ('afﬁnity', 'NN', 'B-NP'),\n",
      " ('elementwise', 'NN', 'B-NP'),\n",
      " ('multiplication', 'NN', 'B-NP'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('To', 'TO', 'O'),\n",
      " ('best', 'VB', 'O'),\n",
      " ('knowledge', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('ﬁrst', 'NNP', 'O'),\n",
      " ('work', 'NN', 'B-NP'),\n",
      " ('zeroshot', 'NN', 'B-NP'),\n",
      " ('object', 'JJ', 'B-NP'),\n",
      " ('detection', 'NN', 'I-NP'),\n",
      " ('textual', 'JJ', 'O'),\n",
      " ('descriptions', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('Since', 'IN', 'O'),\n",
      " ('directly', 'RB', 'O'),\n",
      " ('related', 'VBN', 'O'),\n",
      " ('work', 'NN', 'B-NP'),\n",
      " ('literature', 'NN', 'B-NP'),\n",
      " ('', 'JJ', 'B-NP'),\n",
      " ('investigate', 'NN', 'I-NP'),\n",
      " ('plausible', 'JJ', 'O'),\n",
      " ('solutions', 'NNS', 'O'),\n",
      " ('based', 'VBN', 'O'),\n",
      " ('existing', 'VBG', 'O'),\n",
      " ('zeroshot', 'JJ', 'B-NP'),\n",
      " ('ob', 'NN', 'I-NP'),\n",
      " ('ject', 'NN', 'B-NP'),\n",
      " ('detection', 'NN', 'B-NP'),\n",
      " ('fair', 'JJ', 'B-NP'),\n",
      " ('comparison', 'NN', 'I-NP'),\n",
      " ('', 'IN', 'O'),\n",
      " ('We', 'PRP', 'O'),\n",
      " ('conduct', 'VBP', 'O'),\n",
      " ('extensive', 'JJ', 'O'),\n",
      " ('experiments', 'NNS', 'O'),\n",
      " ('three', 'CD', 'O'),\n",
      " ('challenging', 'VBG', 'O'),\n",
      " ('benchmark', 'NN', 'B-NP'),\n",
      " ('datasets', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('The', 'DT', 'O'),\n",
      " ('extensive', 'JJ', 'O'),\n",
      " ('experimental', 'JJ', 'O'),\n",
      " ('results', 'NNS', 'O'),\n",
      " ('conﬁrm', 'VBP', 'O'),\n",
      " ('superiority', 'NN', 'B-NP'),\n",
      " ('proposed', 'VBN', 'O'),\n",
      " ('model', 'NN', 'B-NP'),\n",
      " ('', 'CD', 'O'),\n",
      " ('Introduction', 'NNP', 'O'),\n",
      " ('In', 'IN', 'O'),\n",
      " ('last', 'JJ', 'B-NP'),\n",
      " ('decade', 'NN', 'I-NP'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('researchers', 'NNS', 'O'),\n",
      " ('made', 'VBD', 'O'),\n",
      " ('promising', 'VBG', 'O'),\n",
      " ('progress', 'NN', 'B-NP'),\n",
      " ('object', 'JJ', 'B-NP'),\n",
      " ('detection', 'NN', 'I-NP'),\n",
      " ('Girshick', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2015', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Ren', 'NNP', 'O'),\n",
      " ('et', 'FW', 'O'),\n",
      " ('al', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2015', 'CD', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2017', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Lin', 'NNP', 'O'),\n",
      " ('et', 'FW', 'O'),\n",
      " ('al', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2017', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Most', 'JJS', 'O'),\n",
      " ('achievements', 'NNS', 'O'),\n",
      " ('rely', 'VBP', 'O'),\n",
      " ('collection', 'JJ', 'B-NP'),\n",
      " ('largescale', 'NN', 'I-NP'),\n",
      " ('labeled', 'VBD', 'O'),\n",
      " ('training', 'NN', 'B-NP'),\n",
      " ('data', 'NNS', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Although', 'IN', 'O'),\n",
      " ('searchers', 'NNS', 'O'),\n",
      " ('struggled', 'VBD', 'O'),\n",
      " ('acquire', 'VB', 'O'),\n",
      " ('larger', 'JJR', 'O'),\n",
      " ('datasets', 'NNS', 'O'),\n",
      " ('broader', 'VBP', 'O'),\n",
      " ('set', 'VBN', 'O'),\n",
      " ('categories', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('processing', 'VBG', 'O'),\n",
      " ('procedure', 'NN', 'B-NP'),\n",
      " ('time', 'NN', 'B-NP'),\n",
      " ('consuming', 'VBG', 'O'),\n",
      " ('tedious', 'JJ', 'O'),\n",
      " ('', 'NNS', 'O'),\n",
      " ('Furthermore', 'RB', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('impossible', 'JJ', 'B-NP'),\n",
      " ('col', 'NN', 'I-NP'),\n",
      " ('lect', 'JJ', 'O'),\n",
      " ('enough', 'RB', 'O'),\n",
      " ('training', 'NN', 'B-NP'),\n",
      " ('data', 'NNS', 'O'),\n",
      " ('rare', 'JJ', 'O'),\n",
      " ('concepts', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('ie', 'JJ', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Okapia', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('There', 'EX', 'O'),\n",
      " ('fore', 'RB', 'O'),\n",
      " ('', 'JJ', 'O'),\n",
      " ('challenging', 'VBG', 'O'),\n",
      " ('problem', 'NN', 'B-NP'),\n",
      " ('simultaneously', 'RB', 'O'),\n",
      " ('recog', 'VBZ', 'O'),\n",
      " ('nize', 'JJ', 'B-NP'),\n",
      " ('locate', 'NN', 'I-NP'),\n",
      " ('novel', 'NN', 'B-NP'),\n",
      " ('object', 'JJ', 'O'),\n",
      " ('instances', 'NNS', 'O'),\n",
      " ('training', 'VBG', 'O'),\n",
      " ('samples', 'NNS', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Zeroshot', 'NNP', 'O'),\n",
      " ('learning', 'VBG', 'O'),\n",
      " ('widely', 'RB', 'O'),\n",
      " ('used', 'VBN', 'O'),\n",
      " ('tackle', 'NN', 'B-NP'),\n",
      " ('problem', 'NN', 'B-NP'),\n",
      " ('data', 'NNS', 'O'),\n",
      " ('scarcity', 'NN', 'B-NP'),\n",
      " ('Akata', 'NNP', 'O'),\n",
      " ('et', 'CC', 'O'),\n",
      " ('al', 'JJ', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2016', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Frome', 'NNP', 'O'),\n",
      " ('et', 'FW', 'O'),\n",
      " ('al', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2013', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Lampert', 'NNP', 'O'),\n",
      " ('et', 'FW', 'O'),\n",
      " ('al', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2009', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Zhang', 'NNP', 'O'),\n",
      " ('et', 'FW', 'O'),\n",
      " ('al', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2017', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Zhang', 'NNP', 'O'),\n",
      " ('Saligrama', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2015', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Rahman', 'NNP', 'O'),\n",
      " ('et', 'VBZ', 'O'),\n",
      " ('al', 'JJ', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2018', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Mikolov', 'NNP', 'O'),\n",
      " ('et', 'FW', 'O'),\n",
      " ('al', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2013', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Most', 'NNP', 'O'),\n",
      " ('works', 'VBZ', 'O'),\n",
      " ('focus', 'RB', 'O'),\n",
      " ('concept', 'JJ', 'B-NP'),\n",
      " ('classiﬁca', 'NN', 'I-NP'),\n",
      " ('tion', 'NN', 'B-NP'),\n",
      " ('problem', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Although', 'IN', 'O'),\n",
      " ('remains', 'VBZ', 'O'),\n",
      " ('challenging', 'VBG', 'O'),\n",
      " ('unsolved', 'JJ', 'B-NP'),\n",
      " ('problem', 'NN', 'I-NP'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('still', 'RB', 'O'),\n",
      " ('large', 'JJ', 'B-NP'),\n",
      " ('gap', 'NN', 'I-NP'),\n",
      " ('problem', 'NN', 'B-NP'),\n",
      " ('setting', 'VBG', 'O'),\n",
      " ('realworld', 'JJ', 'O'),\n",
      " ('scenarios', 'NNS', 'O'),\n",
      " ('following', 'VBG', 'O'),\n",
      " ('aspects', 'NNS', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Firstly', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('zeroshot', 'NNP', 'O'),\n",
      " ('learning', 'VBG', 'O'),\n",
      " ('benchmark', 'JJ', 'O'),\n",
      " ('datasets', 'NNS', 'O'),\n",
      " ('Welinder', 'NNP', 'O'),\n",
      " ('et', 'CC', 'O'),\n",
      " ('al', 'JJ', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2010', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Nilsback', 'NNP', 'O'),\n",
      " ('Zisserman', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2008', 'CD', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Russakovsky', 'NNP', 'O'),\n",
      " ('et', 'FW', 'O'),\n",
      " ('al', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2015', 'CD', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('image', 'NN', 'B-NP'),\n",
      " ('one', 'CD', 'O'),\n",
      " ('dominant', 'JJ', 'O'),\n",
      " ('object', 'JJ', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('realworld', 'NN', 'B-NP'),\n",
      " ('applications', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('multiple', 'JJ', 'O'),\n",
      " ('objects', 'NNS', 'O'),\n",
      " ('may', 'MD', 'O'),\n",
      " ('appear', 'VB', 'O'),\n",
      " ('single', 'JJ', 'B-NP'),\n",
      " ('image', 'NN', 'I-NP'),\n",
      " ('', 'VBD', 'O'),\n",
      " ('Secondly', 'RB', 'O'),\n",
      " ('', 'JJ', 'B-NP'),\n",
      " ('zeroshot', 'JJ', 'I-NP'),\n",
      " ('classiﬁcation', 'NN', 'I-NP'),\n",
      " ('methods', 'NNS', 'O'),\n",
      " ('based', 'VBN', 'O'),\n",
      " ('attributes', 'NNS', 'O'),\n",
      " ('semantic', 'JJ', 'O'),\n",
      " ('descriptions', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('directly', 'RB', 'O'),\n",
      " ('applied', 'VBN', 'O'),\n",
      " ('zeroshot', 'JJ', 'B-NP'),\n",
      " ('detection', 'NN', 'I-NP'),\n",
      " ('entire', 'JJ', 'B-NP'),\n",
      " ('scene', 'NN', 'I-NP'),\n",
      " ('image', 'NN', 'B-NP'),\n",
      " ('', 'VBZ', 'O'),\n",
      " ('Thirdly', 'RB', 'O'),\n",
      " ('', 'JJ', 'O'),\n",
      " ('setting', 'VBG', 'O'),\n",
      " ('zeroshot', 'NN', 'B-NP'),\n",
      " ('learning', 'VBG', 'O'),\n",
      " ('consider', 'JJR', 'O'),\n",
      " ('occlusions', 'NNS', 'O'),\n",
      " ('clutter', 'NN', 'B-NP'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('commonly', 'RB', 'O'),\n",
      " ('exist', 'VBP', 'O'),\n",
      " ('realworld', 'NN', 'B-NP'),\n",
      " ('applications', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('To', 'TO', 'O'),\n",
      " ('close', 'VB', 'O'),\n",
      " ('gap', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Rahman', 'NNP', 'O'),\n",
      " ('et', 'VBZ', 'O'),\n",
      " ('al', 'JJ', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('2018', 'CD', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('introduced', 'VBD', 'O'),\n",
      " ('new', 'JJ', 'O'),\n",
      " ('“', 'NNP', 'O'),\n",
      " ('zeroshot', 'NN', 'B-NP'),\n",
      " ('object', 'NN', 'B-NP'),\n",
      " ('detection', 'NN', 'B-NP'),\n",
      " ('”', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('ZSD', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('problem', 'NN', 'B-NP'),\n",
      " ('setting', 'VBG', 'O'),\n",
      " ('method', 'NN', 'B-NP'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('aims', 'VBZ', 'O'),\n",
      " ('concurrently', 'RB', 'O'),\n",
      " ('detecting', 'VBG', 'O'),\n",
      " ('recognizing', 'VBG', 'O'),\n",
      " ('novel', 'JJ', 'B-NP'),\n",
      " ('instance', 'NN', 'I-NP'),\n",
      " ('absence', 'NN', 'B-NP'),\n",
      " ('training', 'NN', 'B-NP'),\n",
      " ('examples', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('Although', 'IN', 'O'),\n",
      " ('datascarcity', 'NN', 'B-NP'),\n",
      " ('challenge', 'NN', 'B-NP'),\n",
      " ('exists', 'VBZ', 'O'),\n",
      " ('large', 'JJ', 'B-NP'),\n",
      " ('num', 'JJ', 'I-NP'),\n",
      " ('ber', 'NN', 'I-NP'),\n",
      " ('categories', 'NNS', 'O'),\n",
      " ('realworld', 'VBP', 'O'),\n",
      " ('applications', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('massive', 'JJ', 'B-NP'),\n",
      " ('amount', 'NN', 'I-NP'),\n",
      " ('textual', 'JJ', 'B-NP'),\n",
      " ('data', 'NN', 'I-NP'),\n",
      " ('categories', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('These', 'DT', 'O'),\n",
      " ('data', 'NNS', 'O'),\n",
      " ('arrive', 'VBP', 'O'),\n",
      " ('form', 'NN', 'B-NP'),\n",
      " ('dictionary', 'JJ', 'O'),\n",
      " ('entries', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('online', 'JJ', 'O'),\n",
      " ('encyclopedias', 'FW', 'O'),\n",
      " ('online', 'JJ', 'O'),\n",
      " ('resources', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('For', 'IN', 'O'),\n",
      " ('example', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('English', 'NNP', 'O'),\n",
      " ('Wikipedia', 'NNP', 'O'),\n",
      " ('5645010', 'CD', 'O'),\n",
      " ('articles', 'NNS', 'O'),\n",
      " ('site', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('provides', 'VBZ', 'O'),\n",
      " ('rich', 'JJ', 'B-NP'),\n",
      " ('knowl', 'NN', 'I-NP'),\n",
      " ('edge', 'NN', 'B-NP'),\n",
      " ('base', 'NN', 'B-NP'),\n",
      " ('different', 'JJ', 'O'),\n",
      " ('topics', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('The', 'DT', 'B-NP'),\n",
      " ('major', 'JJ', 'I-NP'),\n",
      " ('problem', 'NN', 'I-NP'),\n",
      " ('focus', 'NN', 'B-NP'),\n",
      " ('paper', 'NN', 'B-NP'),\n",
      " ('simultaneously', 'RB', 'O'),\n",
      " ('recognize', 'JJ', 'B-NP'),\n",
      " ('locate', 'NN', 'I-NP'),\n",
      " ('novel', 'NN', 'B-NP'),\n",
      " ('object', 'NN', 'B-NP'),\n",
      " ('instances', 'NNS', 'O'),\n",
      " ('using', 'VBG', 'O'),\n",
      " ('purely', 'RB', 'O'),\n",
      " ('unstructured', 'JJ', 'O'),\n",
      " ('textual', 'JJ', 'O'),\n",
      " ('descriptions', 'NNS', 'O'),\n",
      " ('train', 'VBP', 'O'),\n",
      " ('ing', 'VBG', 'O'),\n",
      " ('samples', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('In', 'IN', 'O'),\n",
      " ('words', 'NNS', 'O'),\n",
      " ('', 'JJ', 'B-NP'),\n",
      " ('goal', 'NN', 'I-NP'),\n",
      " ('concurrently', 'RB', 'O'),\n",
      " ('link', 'VBP', 'O'),\n",
      " ('visual', 'JJ', 'B-NP'),\n",
      " ('image', 'NN', 'I-NP'),\n",
      " ('features', 'NNS', 'O'),\n",
      " ('semantic', 'JJ', 'B-NP'),\n",
      " ('label', 'NN', 'I-NP'),\n",
      " ('information', 'NN', 'B-NP'),\n",
      " ('descriptions', 'NNS', 'O'),\n",
      " ('novel', 'VBP', 'O'),\n",
      " ('concepts', 'NNS', 'O'),\n",
      " ('presented', 'VBN', 'O'),\n",
      " ('form', 'JJ', 'O'),\n",
      " ('natural', 'JJ', 'O'),\n",
      " ('languages', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('ie', 'JJ', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('online', 'NN', 'B-NP'),\n",
      " ('encyclopedias', 'NN', 'B-NP'),\n",
      " ('', 'IN', 'O'),\n",
      " ('We', 'PRP', 'O'),\n",
      " ('de', 'VBP', 'O'),\n",
      " ('sign', 'FW', 'O'),\n",
      " ('novel', 'JJ', 'B-NP'),\n",
      " ('deep', 'JJ', 'I-NP'),\n",
      " ('learning', 'NN', 'I-NP'),\n",
      " ('framework', 'NN', 'B-NP'),\n",
      " ('zeroshot', 'JJ', 'B-NP'),\n",
      " ('object', 'NN', 'I-NP'),\n",
      " ('de', 'IN', 'O'),\n",
      " ('tection', 'NN', 'B-NP'),\n",
      " ('textual', 'JJ', 'B-NP'),\n",
      " ('description', 'NN', 'I-NP'),\n",
      " ('', 'VBD', 'O'),\n",
      " ('The', 'DT', 'O'),\n",
      " ('proposed', 'VBN', 'O'),\n",
      " ('network', 'NN', 'B-NP'),\n",
      " ('takes', 'VBZ', 'O'),\n",
      " ('description', 'NN', 'B-NP'),\n",
      " ('image', 'NN', 'B-NP'),\n",
      " ('input', 'NN', 'B-NP'),\n",
      " ('outputs', 'VBZ', 'O'),\n",
      " ('afﬁnities', 'NNS', 'O'),\n",
      " ('description', 'NN', 'B-NP'),\n",
      " ('object', 'VBP', 'O'),\n",
      " ('proposals', 'NNS', 'O'),\n",
      " ('im', 'VBP', 'O'),\n",
      " ('age', 'NN', 'B-NP'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('We', 'PRP', 'O'),\n",
      " ('process', 'VBP', 'O'),\n",
      " ('textual', 'JJ', 'B-NP'),\n",
      " ('description', 'NN', 'I-NP'),\n",
      " ('wordbyword', 'NN', 'B-NP'),\n",
      " ('fashion', 'NN', 'B-NP'),\n",
      " ('wordLSTM', 'NN', 'B-NP'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('For', 'IN', 'O'),\n",
      " ('word', 'NN', 'B-NP'),\n",
      " ('description', 'NN', 'B-NP'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('achieve', 'VBP', 'O'),\n",
      " ('unitlevel', 'JJ', 'O'),\n",
      " ('attentions', 'NNS', 'O'),\n",
      " ('different', 'JJ', 'O'),\n",
      " ('units', 'NNS', 'O'),\n",
      " ('using', 'VBG', 'O'),\n",
      " ('LSTM', 'NNP', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('Each', 'DT', 'B-NP'),\n",
      " ('unit', 'NN', 'I-NP'),\n",
      " ('determines', 'VBZ', 'O'),\n",
      " ('whether', 'IN', 'O'),\n",
      " ('speciﬁc', 'NN', 'B-NP'),\n",
      " ('object', 'NN', 'B-NP'),\n",
      " ('pattern', 'NN', 'B-NP'),\n",
      " ('exists', 'VBZ', 'O'),\n",
      " ('object', 'VBP', 'O'),\n",
      " ('proposal', 'NN', 'B-NP'),\n",
      " ('', 'IN', 'O'),\n",
      " ('The', 'DT', 'O'),\n",
      " ('contributions', 'NNS', 'O'),\n",
      " ('different', 'JJ', 'O'),\n",
      " ('units', 'NNS', 'O'),\n",
      " ('weighted', 'VBD', 'O'),\n",
      " ('visualunit', 'JJ', 'B-NP'),\n",
      " ('attention', 'NN', 'I-NP'),\n",
      " ('mechanism', 'NN', 'B-NP'),\n",
      " ('', 'VBZ', 'O'),\n",
      " ('To', 'TO', 'O'),\n",
      " ('step', 'VB', 'O'),\n",
      " ('', 'NNP', 'O'),\n",
      " ('also', 'RB', 'O'),\n",
      " ('study', 'VBP', 'O'),\n",
      " ('wordlevel', 'JJ', 'B-NP'),\n",
      " ('attention', 'NN', 'I-NP'),\n",
      " ('learns', 'VBZ', 'O'),\n",
      " ('importance', 'JJ', 'O'),\n",
      " ('different', 'JJ', 'O'),\n",
      " ('words', 'NNS', 'O'),\n",
      " ('adaptive', 'JJ', 'B-NP'),\n",
      " ('wordlevel', 'NN', 'I-NP'),\n",
      " ('weighting', 'VBG', 'O'),\n",
      " ('', 'NN', 'B-NP'),\n",
      " ('We', 'PRP', 'O'),\n",
      " ('achieve', 'VBP', 'O'),\n",
      " ('ﬁnal', 'JJ', 'B-NP'),\n",
      " ('afﬁnity', 'NN', 'I-NP'),\n",
      " ('averaging', 'VBG', 'O'),\n",
      " ('units', 'NNS', 'O'),\n",
      " ('’', 'VBP', 'O'),\n",
      " ('responses', 'NNS', 'O'),\n",
      " ('words', 'NNS', 'O'),\n",
      " ('', 'VBP', 'O'),\n",
      " ('We', 'PRP', 'O'),\n",
      " ('conduct', 'VBP', 'O'),\n",
      " ('experiments', 'NNS', 'O'),\n",
      " ('conﬁrm', 'VBP', 'O'),\n",
      " ('visual', 'JJ', 'B-NP'),\n",
      " ('unitlevel', 'JJ', 'I-NP'),\n",
      " ('attention', 'NN', 'I-NP'),\n",
      " ('wordlevel', 'NN', 'B-NP'),\n",
      " ('attention', 'NN', 'B-NP'),\n",
      " ('contribute', 'NN', 'B-NP'),\n",
      " ('good', 'JJ', 'B-NP'),\n",
      " ('performance', 'NN', 'I-NP'),\n",
      " ('proposed', 'VBN', 'O'),\n",
      " ('model', 'NN', 'B-NP'),\n",
      " ('', 'NNS', 'O'),\n",
      " ('Compared', 'NNP', 'O'),\n",
      " ('related', 'VBD', 'O'),\n",
      " ('works', 'NNS', 'O'),\n",
      " ('literature', 'NN', 'B-NP'),\n",
      " ('', 'NN', 'B-NP')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eca03b0f-c6cf-48e3-89c6-ca4700c42302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list1 = [10,20,30,40]\n",
    "list2 = [40,30,20,10]\n",
    "col1 = \"X\"\n",
    "col2 = \"Y\"\n",
    "data = pd.DataFrame({col1:list1,col2:list2})\n",
    "data.to_excel('sample_data.xlsx', sheet_name='sheet1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e64068-db87-4855-9fbf-fbaa45e65d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZeroShot Object Detection Textual Descriptions Zhihui Li1  Lina Yao1  Xiaoqin Zhang2  Xianzhi Wang3  Salil Kanhere1  Huaxiang Zhang4∗ 1School Computer Science Engineering  University New South Wales 2College Mathematics Information Science  Wenzhou University 3School Software  University Technology Sydney 4School Information Science Engineering  Shandong Normal University Abstract Object detection important realworld applications  Exist ing methods mainly focus object detection sufﬁcient labelled training data zeroshot object detection concept names  In paper  address challenging prob lem zeroshot object detection natural language de scription  aims simultaneously detect recognize novel concept instances textual descriptions  We propose novel deep learning framework jointly learn visual units  visualunit attention wordlevel attention  com bined achieve wordproposal afﬁnity elementwise multiplication  To best knowledge  ﬁrst work zeroshot object detection textual descriptions  Since directly related work literature  investigate plausible solutions based existing zeroshot ob ject detection fair comparison  We conduct extensive experiments three challenging benchmark datasets  The extensive experimental results conﬁrm superiority proposed model  Introduction In last decade  researchers made promising progress object detection Girshick  2015   Ren et al   2015  2017   Lin et al   2017   Most achievements rely collection largescale labeled training data  Although searchers struggled acquire larger datasets broader set categories  processing procedure time consuming tedious  Furthermore  impossible col lect enough training data rare concepts  ie  Okapia  There fore  challenging problem simultaneously recog nize locate novel object instances training samples  Zeroshot learning widely used tackle problem data scarcity Akata et al   2016   Frome et al   2013   Lampert et al   2009   Zhang et al   2017   Zhang Saligrama  2015   Rahman et al   2018   Mikolov et al   2013   Most works focus concept classiﬁca tion problem  Although remains challenging unsolved problem  still large gap problem setting realworld scenarios following aspects  Firstly  zeroshot learning benchmark datasets Welinder et al   2010   Nilsback Zisserman  2008   Russakovsky et al   2015   image one dominant object  realworld applications  multiple objects may appear single image  Secondly  zeroshot classiﬁcation methods based attributes semantic descriptions  directly applied zeroshot detection entire scene image  Thirdly  setting zeroshot learning consider occlusions clutter  commonly exist realworld applications  To close gap  Rahman et al   2018  introduced new “ zeroshot object detection ”  ZSD  problem setting method  aims concurrently detecting recognizing novel instance absence training examples  Although datascarcity challenge exists large num ber categories realworld applications  massive amount textual data categories  These data arrive form dictionary entries  online encyclopedias online resources  For example  English Wikipedia 5645010 articles site  provides rich knowl edge base different topics  The major problem focus paper simultaneously recognize locate novel object instances using purely unstructured textual descriptions train ing samples  In words  goal concurrently link visual image features semantic label information descriptions novel concepts presented form natural languages  ie  online encyclopedias  We de sign novel deep learning framework zeroshot object de tection textual description  The proposed network takes description image input outputs afﬁnities description object proposals im age  We process textual description wordbyword fashion wordLSTM  For word description  achieve unitlevel attentions different units using LSTM  Each unit determines whether speciﬁc object pattern exists object proposal  The contributions different units weighted visualunit attention mechanism  To step  also study wordlevel attention learns importance different words adaptive wordlevel weighting  We achieve ﬁnal afﬁnity averaging units ’ responses words  We conduct experiments conﬁrm visual unitlevel attention wordlevel attention contribute good performance proposed model  Compared related works literature '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(exmpl_filtered_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e01107c-51de-4972-9b42-7f992d82c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Zero-Shot Object Detection with Textual Descriptions</br>Zhihui Li1, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lina Yao1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Xiaoqin Zhang2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Xianzhi Wang3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Salil Kanhere1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Huaxiang\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " Zhang4∗</br>1School of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Computer Science and Engineering,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    University of New South Wales\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2College\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of Mathematics and Information Science, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wenzhou University\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>3School of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Software\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    University of Technology Sydney\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>4School of Information Science and Engineering, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Shandong Normal University\n",
       "Abstract\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>Object detection is important in real-world applications. Exist-</br>ing methods mainly focus on object detection with sufﬁcient </br>labelled training data or \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot object detection with only </br>concept names. In this paper, we address the challenging prob-</br>lem of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot object detection with natural language de-</br>scription, which aims to simultaneously detect and recognize </br>novel concept instances with textual descriptions. We propose </br>a novel deep learning framework to jointly learn visual units, </br>visual-unit attention and word-level attention, which are com-</br>bined to achieve word-proposal afﬁnity by an element-wise </br>multiplication. To the best of our knowledge, this is the ﬁrst </br>work on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot object detection with textual descriptions. </br>Since there is no directly related work in the literature, we </br>investigate plausible solutions based on existing \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot ob-</br>ject detection for a fair comparison. We conduct extensive </br>experiments on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " challenging benchmark datasets. The </br>extensive experimental results conﬁrm the superiority of the </br>proposed model.</br>Introduction</br>In \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last decade\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", researchers have made promising progress </br>in object detection \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Girshick\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " [2015], \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ren et al\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". [\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2015\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2017\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "], </br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lin et al.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " [\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2017\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "]. Most of these achievements rely on the </br>collection of large-scale labeled training data. Although re-</br>searchers have struggled to acquire larger datasets with a </br>broader set of categories, the processing procedure is time-</br>consuming and tedious. Furthermore, it is impossible to col-</br>lect enough training data for rare concepts, i.e. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Okapia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". There-</br>fore, a challenging problem is how to simultaneously recog-</br>nize and locate these novel object instances with no training </br>samples.</br>\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot learning has been widely used to tackle the </br>problem of data scarcity \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akata et al.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " [2016], Frome et al.</br>[2013], \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lampert et al.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " [\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2009\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "], \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zhang et al.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " [\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2017\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "], Zhang </br>and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Saligrama\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " [2015], \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rahman et al\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". [2018], \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mikolov et al.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</br>[2013]. Most of these works focus on the concept classiﬁca-</br>tion problem. Although it remains a challenging and unsolved </br>problem, there is still a large gap between the problem setting </br>and real-world scenarios in the following aspects. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Firstly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       ", in </br>most \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot learning benchmark datasets \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Welinder et al.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</br>[2010], \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nilsback\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zisserman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " [2008], \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Russakovsky et al.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</br>[2015], each image has \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    only one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " dominant object, while in</br>real-world applications, multiple objects may appear in a</br>single image. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Secondly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       ", most of the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot classiﬁcation</br>methods are based on attributes and semantic descriptions,</br>which cannot be directly applied to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot detection in the</br>entire scene image. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thirdly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       ", the setting of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot learning</br>does not consider occlusions and clutter, which commonly</br>exist in real-world applications. To close this gap, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rahman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</br>et al. [\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2018\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "] introduced a new “\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot object detection”</br>(\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ZSD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ") problem setting method, which aims at concurrently</br>detecting and recognizing novel instance in the absence of</br>any training examples.</br>Although the data-scarcity challenge exists for a large num-</br>ber of categories in real-world applications, there is a massive</br>amount of \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    textual\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " data for these categories. These data arrive</br>in the form of dictionary entries, online encyclopedias and</br>other online resources. For example, English \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wikipedia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has</br>\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5,645,010\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " articles on its site, which provides a rich knowl-</br>edge base for different topics.</br>The major problem we focus on in this paper is how to</br>simultaneously recognize and locate novel object instances</br>using purely unstructured textual descriptions with no train-</br>ing samples. In other words, our goal is to concurrently link</br>visual image features with the semantic label information</br>where the descriptions of novel concepts are presented in the</br>form of natural languages, i.e. online encyclopedias. We de-</br>sign a novel deep learning framework for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    zero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-shot object de-</br>tection with textual description. The proposed network takes</br>a description and an image as input and outputs the afﬁnities</br>between the description and the object proposals in the im-</br>age. We process the textual description in a word-by-word</br>fashion with word-LSTM. For each word in the description,</br>we achieve unit-level attentions for different units using the</br>LSTM. Each unit determines whether a speciﬁc object pattern</br>exists in the object proposal. The contributions of different</br>units are weighted by the visual-unit attention mechanism. To</br>step further, we also study word-level attention which learns</br>the importance of different words for adaptive word-level</br>weighting. We achieve the ﬁnal afﬁnity by averaging over all</br>units’ responses for all words. We conduct experiments to</br>conﬁrm that both visual unit-level attention and word-level</br>attention contribute to the good performance of the proposed</br>model. Compared with the related works in the literature,</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text1 = NER(exmpl)\n",
    "displacy.render(text1,style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dcf850-fc6b-418a-ba21-b55e375eba18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baab7d3-319f-4b3f-b11c-908a3c99343f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
